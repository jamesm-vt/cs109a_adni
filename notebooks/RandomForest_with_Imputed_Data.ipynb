{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Random Forest\n",
    "(Shristi Pandey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime\n",
    "import numpy as np \n",
    "import scipy as sp\n",
    "from scipy.stats import mode\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b4_impute = pd.read_csv(\"../data/Per_Patient/pat_merge_b4_impute.csv\")\n",
    "data_model_50pc = pd.read_csv(\"../data/Imputed/data_modeled_upto_50pct_missing.csv\")\n",
    "data_model_30pc = pd.read_csv(\"../data/Imputed/data_modeled_upto_30pct_missing.csv\")\n",
    "data_model_100pc = pd.read_csv(\"../data/Imputed/data_modeled_upto_100pct_missing.csv\")\n",
    "data_mean_30pc = pd.read_csv(\"../data/Imputed/data_mean_upto_30pct_missing.csv\")\n",
    "data_mean_50pc = pd.read_csv(\"../data/Imputed/data_mean_upto_50pct_missing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data_model_100pc.columns))\n",
    "len(data_b4_impute.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>FDG</th>\n",
       "      <th>AV45</th>\n",
       "      <th>ABETA</th>\n",
       "      <th>TAU</th>\n",
       "      <th>PTAU</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>ADAS11</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>ADASQ4</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>RAVLT_immediate</th>\n",
       "      <th>RAVLT_learning</th>\n",
       "      <th>RAVLT_forgetting</th>\n",
       "      <th>RAVLT_perc_forgetting</th>\n",
       "      <th>LDELTOTAL</th>\n",
       "      <th>TRABSCOR</th>\n",
       "      <th>FAQ</th>\n",
       "      <th>MOCA</th>\n",
       "      <th>EcogPtMem</th>\n",
       "      <th>EcogPtLang</th>\n",
       "      <th>EcogPtVisspat</th>\n",
       "      <th>EcogPtPlan</th>\n",
       "      <th>EcogPtOrgan</th>\n",
       "      <th>EcogPtDivatt</th>\n",
       "      <th>EcogPtTotal</th>\n",
       "      <th>EcogSPMem</th>\n",
       "      <th>EcogSPLang</th>\n",
       "      <th>EcogSPVisspat</th>\n",
       "      <th>EcogSPPlan</th>\n",
       "      <th>EcogSPOrgan</th>\n",
       "      <th>EcogSPDivatt</th>\n",
       "      <th>EcogSPTotal</th>\n",
       "      <th>Ventricles</th>\n",
       "      <th>Hippocampus</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>ICV</th>\n",
       "      <th>mPACCdigit</th>\n",
       "      <th>mPACCtrailsB</th>\n",
       "      <th>Month</th>\n",
       "      <th>APGEN1</th>\n",
       "      <th>APGEN2</th>\n",
       "      <th>BCVOMIT</th>\n",
       "      <th>BCENERGY</th>\n",
       "      <th>...</th>\n",
       "      <th>HMT40</th>\n",
       "      <th>HMT15</th>\n",
       "      <th>RCT6</th>\n",
       "      <th>RCT392</th>\n",
       "      <th>HMT13</th>\n",
       "      <th>HMT19</th>\n",
       "      <th>RCT20</th>\n",
       "      <th>RCT8</th>\n",
       "      <th>RCT12</th>\n",
       "      <th>HMT9</th>\n",
       "      <th>RCT29</th>\n",
       "      <th>HMT18</th>\n",
       "      <th>RCT11</th>\n",
       "      <th>BAT126</th>\n",
       "      <th>HMT102</th>\n",
       "      <th>RCT14</th>\n",
       "      <th>MH9ENDO</th>\n",
       "      <th>MH7DERM</th>\n",
       "      <th>MH15DRUG</th>\n",
       "      <th>MH4CARD</th>\n",
       "      <th>MH18SURG</th>\n",
       "      <th>MH16SMOK</th>\n",
       "      <th>MH11HEMA</th>\n",
       "      <th>MH13ALLE</th>\n",
       "      <th>MH12RENA</th>\n",
       "      <th>MH3HEAD</th>\n",
       "      <th>MH17MALI</th>\n",
       "      <th>MH10GAST</th>\n",
       "      <th>MHPSYCH</th>\n",
       "      <th>MH6HEPAT</th>\n",
       "      <th>MH5RESP</th>\n",
       "      <th>MH14ALCH</th>\n",
       "      <th>MH2NEURL</th>\n",
       "      <th>MH8MUSCL</th>\n",
       "      <th>HMSCORE</th>\n",
       "      <th>MMSCORE</th>\n",
       "      <th>NXVISUAL</th>\n",
       "      <th>NXAUDITO</th>\n",
       "      <th>NXMOTOR</th>\n",
       "      <th>NXCONSCI</th>\n",
       "      <th>NXFINGER</th>\n",
       "      <th>NXABNORM</th>\n",
       "      <th>NXNERVE</th>\n",
       "      <th>NXTREMOR</th>\n",
       "      <th>NXGAIT</th>\n",
       "      <th>NXOTHER</th>\n",
       "      <th>NXPLANTA</th>\n",
       "      <th>NXSENSOR</th>\n",
       "      <th>NXTENDON</th>\n",
       "      <th>NXHEEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.0</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.00000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3184.250363</td>\n",
       "      <td>0.512990</td>\n",
       "      <td>0.752603</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.536265</td>\n",
       "      <td>0.319630</td>\n",
       "      <td>0.518807</td>\n",
       "      <td>0.169792</td>\n",
       "      <td>0.175688</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>0.254211</td>\n",
       "      <td>0.299899</td>\n",
       "      <td>0.500679</td>\n",
       "      <td>0.783051</td>\n",
       "      <td>0.514344</td>\n",
       "      <td>0.621096</td>\n",
       "      <td>0.749577</td>\n",
       "      <td>0.910976</td>\n",
       "      <td>0.336693</td>\n",
       "      <td>0.387486</td>\n",
       "      <td>0.127323</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.334067</td>\n",
       "      <td>0.224522</td>\n",
       "      <td>0.113264</td>\n",
       "      <td>0.120317</td>\n",
       "      <td>0.157714</td>\n",
       "      <td>0.248965</td>\n",
       "      <td>0.220020</td>\n",
       "      <td>0.309481</td>\n",
       "      <td>0.175611</td>\n",
       "      <td>0.131741</td>\n",
       "      <td>0.162294</td>\n",
       "      <td>0.188315</td>\n",
       "      <td>0.247378</td>\n",
       "      <td>0.207109</td>\n",
       "      <td>0.241021</td>\n",
       "      <td>0.467491</td>\n",
       "      <td>0.430901</td>\n",
       "      <td>0.488354</td>\n",
       "      <td>0.394462</td>\n",
       "      <td>0.438367</td>\n",
       "      <td>0.426257</td>\n",
       "      <td>0.603510</td>\n",
       "      <td>0.591558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.001937</td>\n",
       "      <td>3.389346</td>\n",
       "      <td>1.009685</td>\n",
       "      <td>1.173850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359411</td>\n",
       "      <td>0.535965</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>0.257332</td>\n",
       "      <td>0.320509</td>\n",
       "      <td>0.188639</td>\n",
       "      <td>0.270699</td>\n",
       "      <td>0.373022</td>\n",
       "      <td>0.348177</td>\n",
       "      <td>0.133654</td>\n",
       "      <td>0.104543</td>\n",
       "      <td>0.077540</td>\n",
       "      <td>0.127020</td>\n",
       "      <td>0.071207</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.037438</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.261017</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.784504</td>\n",
       "      <td>0.333172</td>\n",
       "      <td>0.073608</td>\n",
       "      <td>0.353511</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.198063</td>\n",
       "      <td>0.376271</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.030993</td>\n",
       "      <td>0.179661</td>\n",
       "      <td>0.036804</td>\n",
       "      <td>0.243584</td>\n",
       "      <td>0.718160</td>\n",
       "      <td>0.100161</td>\n",
       "      <td>0.782744</td>\n",
       "      <td>1.050847</td>\n",
       "      <td>1.093947</td>\n",
       "      <td>1.032930</td>\n",
       "      <td>1.001453</td>\n",
       "      <td>1.02615</td>\n",
       "      <td>1.000969</td>\n",
       "      <td>1.046005</td>\n",
       "      <td>1.111864</td>\n",
       "      <td>1.102663</td>\n",
       "      <td>1.047458</td>\n",
       "      <td>1.019855</td>\n",
       "      <td>1.132688</td>\n",
       "      <td>1.133172</td>\n",
       "      <td>1.016465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2219.977926</td>\n",
       "      <td>0.194470</td>\n",
       "      <td>0.174440</td>\n",
       "      <td>0.644339</td>\n",
       "      <td>0.124683</td>\n",
       "      <td>0.134817</td>\n",
       "      <td>0.237267</td>\n",
       "      <td>0.084695</td>\n",
       "      <td>0.101588</td>\n",
       "      <td>0.176336</td>\n",
       "      <td>0.149086</td>\n",
       "      <td>0.165281</td>\n",
       "      <td>0.293897</td>\n",
       "      <td>0.218411</td>\n",
       "      <td>0.180730</td>\n",
       "      <td>0.139059</td>\n",
       "      <td>0.063423</td>\n",
       "      <td>0.073210</td>\n",
       "      <td>0.237972</td>\n",
       "      <td>0.244101</td>\n",
       "      <td>0.201257</td>\n",
       "      <td>0.130931</td>\n",
       "      <td>0.195748</td>\n",
       "      <td>0.169904</td>\n",
       "      <td>0.140091</td>\n",
       "      <td>0.144709</td>\n",
       "      <td>0.163598</td>\n",
       "      <td>0.198715</td>\n",
       "      <td>0.153049</td>\n",
       "      <td>0.247174</td>\n",
       "      <td>0.190226</td>\n",
       "      <td>0.181918</td>\n",
       "      <td>0.202654</td>\n",
       "      <td>0.224112</td>\n",
       "      <td>0.243581</td>\n",
       "      <td>0.194971</td>\n",
       "      <td>0.143820</td>\n",
       "      <td>0.133440</td>\n",
       "      <td>0.124693</td>\n",
       "      <td>0.146943</td>\n",
       "      <td>0.116968</td>\n",
       "      <td>0.120736</td>\n",
       "      <td>0.151339</td>\n",
       "      <td>0.211086</td>\n",
       "      <td>0.194493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404668</td>\n",
       "      <td>0.492662</td>\n",
       "      <td>0.097960</td>\n",
       "      <td>0.379072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088243</td>\n",
       "      <td>0.129019</td>\n",
       "      <td>0.107760</td>\n",
       "      <td>0.105834</td>\n",
       "      <td>0.119489</td>\n",
       "      <td>0.098523</td>\n",
       "      <td>0.089468</td>\n",
       "      <td>0.133733</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.053720</td>\n",
       "      <td>0.131333</td>\n",
       "      <td>0.049675</td>\n",
       "      <td>0.055458</td>\n",
       "      <td>0.061996</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.032463</td>\n",
       "      <td>0.480342</td>\n",
       "      <td>0.439296</td>\n",
       "      <td>0.079113</td>\n",
       "      <td>0.444680</td>\n",
       "      <td>0.411266</td>\n",
       "      <td>0.471462</td>\n",
       "      <td>0.261195</td>\n",
       "      <td>0.478175</td>\n",
       "      <td>0.480342</td>\n",
       "      <td>0.464343</td>\n",
       "      <td>0.398636</td>\n",
       "      <td>0.484567</td>\n",
       "      <td>0.451863</td>\n",
       "      <td>0.173340</td>\n",
       "      <td>0.383998</td>\n",
       "      <td>0.188326</td>\n",
       "      <td>0.429348</td>\n",
       "      <td>0.450005</td>\n",
       "      <td>0.117805</td>\n",
       "      <td>0.218489</td>\n",
       "      <td>0.219739</td>\n",
       "      <td>0.291825</td>\n",
       "      <td>0.178496</td>\n",
       "      <td>0.038097</td>\n",
       "      <td>0.15962</td>\n",
       "      <td>0.031114</td>\n",
       "      <td>0.209546</td>\n",
       "      <td>0.315276</td>\n",
       "      <td>0.303592</td>\n",
       "      <td>0.212667</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.339319</td>\n",
       "      <td>0.339843</td>\n",
       "      <td>0.127286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>913.000000</td>\n",
       "      <td>0.381081</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493359</td>\n",
       "      <td>0.234992</td>\n",
       "      <td>0.362600</td>\n",
       "      <td>0.126721</td>\n",
       "      <td>0.119196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148348</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.111110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055557</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.121294</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056523</td>\n",
       "      <td>0.142442</td>\n",
       "      <td>0.393463</td>\n",
       "      <td>0.357351</td>\n",
       "      <td>0.413423</td>\n",
       "      <td>0.331648</td>\n",
       "      <td>0.378189</td>\n",
       "      <td>0.328496</td>\n",
       "      <td>0.451378</td>\n",
       "      <td>0.451947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319672</td>\n",
       "      <td>0.473214</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.253933</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.220207</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.103647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.100559</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4146.000000</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536265</td>\n",
       "      <td>0.319630</td>\n",
       "      <td>0.518807</td>\n",
       "      <td>0.169792</td>\n",
       "      <td>0.175688</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.226623</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.334067</td>\n",
       "      <td>0.224522</td>\n",
       "      <td>0.113264</td>\n",
       "      <td>0.120317</td>\n",
       "      <td>0.157714</td>\n",
       "      <td>0.248965</td>\n",
       "      <td>0.220020</td>\n",
       "      <td>0.309481</td>\n",
       "      <td>0.175611</td>\n",
       "      <td>0.131741</td>\n",
       "      <td>0.162294</td>\n",
       "      <td>0.188315</td>\n",
       "      <td>0.247378</td>\n",
       "      <td>0.207109</td>\n",
       "      <td>0.241021</td>\n",
       "      <td>0.467491</td>\n",
       "      <td>0.430901</td>\n",
       "      <td>0.488354</td>\n",
       "      <td>0.394462</td>\n",
       "      <td>0.438367</td>\n",
       "      <td>0.426257</td>\n",
       "      <td>0.643316</td>\n",
       "      <td>0.636468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359411</td>\n",
       "      <td>0.535965</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>0.257332</td>\n",
       "      <td>0.320509</td>\n",
       "      <td>0.188639</td>\n",
       "      <td>0.270699</td>\n",
       "      <td>0.373022</td>\n",
       "      <td>0.348177</td>\n",
       "      <td>0.133654</td>\n",
       "      <td>0.104543</td>\n",
       "      <td>0.077540</td>\n",
       "      <td>0.127020</td>\n",
       "      <td>0.069845</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.037438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4958.000000</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593204</td>\n",
       "      <td>0.319630</td>\n",
       "      <td>0.521733</td>\n",
       "      <td>0.169792</td>\n",
       "      <td>0.175688</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.328099</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.259260</td>\n",
       "      <td>0.113264</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.233252</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.175611</td>\n",
       "      <td>0.131741</td>\n",
       "      <td>0.162294</td>\n",
       "      <td>0.188315</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.207109</td>\n",
       "      <td>0.288869</td>\n",
       "      <td>0.550576</td>\n",
       "      <td>0.504479</td>\n",
       "      <td>0.572270</td>\n",
       "      <td>0.450308</td>\n",
       "      <td>0.501534</td>\n",
       "      <td>0.505042</td>\n",
       "      <td>0.772411</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401639</td>\n",
       "      <td>0.605357</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.364045</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.310881</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.148752</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.128492</td>\n",
       "      <td>0.071207</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6582.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               RID          AGE     PTEDUCAT        APOE4          FDG         AV45        ABETA          TAU         PTAU        CDRSB       ADAS11       ADAS13       ADASQ4         MMSE  RAVLT_immediate  RAVLT_learning  RAVLT_forgetting  RAVLT_perc_forgetting    LDELTOTAL     TRABSCOR          FAQ         MOCA    EcogPtMem   EcogPtLang  EcogPtVisspat   EcogPtPlan  EcogPtOrgan  EcogPtDivatt  EcogPtTotal    EcogSPMem   EcogSPLang  EcogSPVisspat   EcogSPPlan  EcogSPOrgan  EcogSPDivatt  EcogSPTotal   Ventricles  Hippocampus   WholeBrain   Entorhinal     Fusiform      MidTemp          ICV   mPACCdigit  mPACCtrailsB   Month       APGEN1       APGEN2      BCVOMIT     BCENERGY     ...             HMT40        HMT15         RCT6       RCT392        HMT13        HMT19        RCT20         RCT8        RCT12         HMT9        RCT29        HMT18        RCT11       BAT126       HMT102        RCT14      MH9ENDO      MH7DERM     MH15DRUG      MH4CARD     MH18SURG     MH16SMOK     MH11HEMA     MH13ALLE     MH12RENA      MH3HEAD     MH17MALI     MH10GAST      MHPSYCH     MH6HEPAT      MH5RESP     MH14ALCH     MH2NEURL     MH8MUSCL      HMSCORE      MMSCORE     NXVISUAL     NXAUDITO      NXMOTOR     NXCONSCI    NXFINGER     NXABNORM      NXNERVE     NXTREMOR       NXGAIT      NXOTHER     NXPLANTA     NXSENSOR     NXTENDON       NXHEEL\n",
       "count  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000      2065.000000     2065.000000       2065.000000            2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000    2065.000000  2065.000000  2065.000000   2065.000000  2065.000000  2065.000000  2065.000000    2065.000000  2065.000000  2065.000000   2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000   2065.000000  2065.0  2065.000000  2065.000000  2065.000000  2065.000000     ...       2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.00000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000  2065.000000\n",
       "mean   3184.250363     0.512990     0.752603     0.474576     0.536265     0.319630     0.518807     0.169792     0.175688     0.145956     0.254211     0.299899     0.500679     0.783051         0.514344        0.621096          0.749577               0.910976     0.336693     0.387486     0.127323     0.759982     0.334067     0.224522       0.113264     0.120317     0.157714      0.248965     0.220020     0.309481     0.175611       0.131741     0.162294     0.188315      0.247378     0.207109     0.241021     0.467491     0.430901     0.488354     0.394462     0.438367     0.426257     0.603510      0.591558     0.0     3.001937     3.389346     1.009685     1.173850     ...          0.359411     0.535965     0.295411     0.257332     0.320509     0.188639     0.270699     0.373022     0.348177     0.133654     0.104543     0.077540     0.127020     0.071207     0.481622     0.037438     0.360775     0.261017     0.006295     0.728814     0.784504     0.333172     0.073608     0.353511     0.360775     0.685714     0.198063     0.376271     0.285714     0.030993     0.179661     0.036804     0.243584     0.718160     0.100161     0.782744     1.050847     1.093947     1.032930     1.001453     1.02615     1.000969     1.046005     1.111864     1.102663     1.047458     1.019855     1.132688     1.133172     1.016465\n",
       "std    2219.977926     0.194470     0.174440     0.644339     0.124683     0.134817     0.237267     0.084695     0.101588     0.176336     0.149086     0.165281     0.293897     0.218411         0.180730        0.139059          0.063423               0.073210     0.237972     0.244101     0.201257     0.130931     0.195748     0.169904       0.140091     0.144709     0.163598      0.198715     0.153049     0.247174     0.190226       0.181918     0.202654     0.224112      0.243581     0.194971     0.143820     0.133440     0.124693     0.146943     0.116968     0.120736     0.151339     0.211086      0.194493     0.0     0.404668     0.492662     0.097960     0.379072     ...          0.088243     0.129019     0.107760     0.105834     0.119489     0.098523     0.089468     0.133733     0.096200     0.053720     0.131333     0.049675     0.055458     0.061996     0.153088     0.032463     0.480342     0.439296     0.079113     0.444680     0.411266     0.471462     0.261195     0.478175     0.480342     0.464343     0.398636     0.484567     0.451863     0.173340     0.383998     0.188326     0.429348     0.450005     0.117805     0.218489     0.219739     0.291825     0.178496     0.038097     0.15962     0.031114     0.209546     0.315276     0.303592     0.212667     0.139535     0.339319     0.339843     0.127286\n",
       "min       2.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000         0.000000        0.000000          0.000000               0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000       0.000000     0.000000     0.000000      0.000000     0.000000     0.000000     0.000000       0.000000     0.000000     0.000000      0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000      0.000000     0.0     2.000000     2.000000     1.000000     1.000000     ...          0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     1.000000     1.000000     1.000000     1.000000     1.00000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "25%     913.000000     0.381081     0.625000     0.000000     0.493359     0.234992     0.362600     0.126721     0.119196     0.000000     0.148348     0.178571     0.300000     0.666667         0.380282        0.500000          0.720930               0.853333     0.130435     0.220000     0.000000     0.730769     0.208333     0.111110       0.000000     0.000000     0.055557      0.083333     0.121294     0.125000     0.037037       0.000000     0.000000     0.000000      0.000000     0.056523     0.142442     0.393463     0.357351     0.413423     0.331648     0.378189     0.328496     0.451378      0.451947     0.0     3.000000     3.000000     1.000000     1.000000     ...          0.319672     0.473214     0.227273     0.210526     0.253933     0.125000     0.220207     0.292135     0.300000     0.103647     0.000000     0.051724     0.100559     0.040579     0.428571     0.021591     0.000000     0.000000     0.000000     0.000000     1.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.666667     1.000000     1.000000     1.000000     1.000000     1.00000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "50%    4146.000000     0.513514     0.750000     0.000000     0.536265     0.319630     0.518807     0.169792     0.175688     0.100000     0.226623     0.267857     0.500000     0.833333         0.507042        0.600000          0.744186               0.911111     0.347826     0.303333     0.033333     0.759982     0.334067     0.224522       0.113264     0.120317     0.157714      0.248965     0.220020     0.309481     0.175611       0.131741     0.162294     0.188315      0.247378     0.207109     0.241021     0.467491     0.430901     0.488354     0.394462     0.438367     0.426257     0.643316      0.636468     0.0     3.000000     3.000000     1.000000     1.000000     ...          0.359411     0.535965     0.295411     0.257332     0.320509     0.188639     0.270699     0.373022     0.348177     0.133654     0.104543     0.077540     0.127020     0.069845     0.481622     0.037438     0.000000     0.000000     0.000000     1.000000     1.000000     0.000000     0.000000     0.000000     0.000000     1.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     1.000000     0.166667     0.833333     1.000000     1.000000     1.000000     1.000000     1.00000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "75%    4958.000000     0.648649     0.875000     1.000000     0.593204     0.319630     0.521733     0.169792     0.175688     0.200000     0.328099     0.392857     0.700000     0.916667         0.647887        0.700000          0.790698               1.000000     0.521739     0.450000     0.166667     0.846154     0.375000     0.259260       0.113264     0.133333     0.166667      0.250000     0.233252     0.333333     0.175611       0.131741     0.162294     0.188315      0.250000     0.207109     0.288869     0.550576     0.504479     0.572270     0.450308     0.501534     0.505042     0.772411      0.744214     0.0     3.000000     4.000000     1.000000     1.000000     ...          0.401639     0.605357     0.340909     0.315789     0.364045     0.200000     0.310881     0.438202     0.400000     0.148752     0.250000     0.086207     0.128492     0.071207     0.571429     0.039015     1.000000     1.000000     0.000000     1.000000     1.000000     1.000000     0.000000     1.000000     1.000000     1.000000     0.000000     1.000000     1.000000     0.000000     0.000000     0.000000     0.000000     1.000000     0.166667     0.916667     1.000000     1.000000     1.000000     1.000000     1.00000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "max    6582.000000     1.000000     1.000000     2.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000         1.000000        1.000000          1.000000               1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000       1.000000     1.000000     1.000000      1.000000     1.000000     1.000000     1.000000       1.000000     1.000000     1.000000      1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000      1.000000     0.0     4.000000     4.000000     2.000000     2.000000     ...          1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     2.000000     2.000000     2.000000     2.000000     2.00000     2.000000     2.000000     2.000000     2.000000     2.000000     2.000000     2.000000     2.000000     2.000000\n",
       "\n",
       "[8 rows x 160 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean_50pc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first use the imputed dataset to generate a tree based model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data: \n",
    "to_drop = ['DX_BASE_2.0', 'DX_BASE_3.0',  'DX_bl_CN', \n",
    "           'DX_bl_MCI', 'DX_FINAL_2.0', 'DX_FINAL_3.0', 'DXCOMB_2.0', 'DXCOMB_3.0']\n",
    "\n",
    "\n",
    "def prepare_data (data, to_drop):\n",
    "    #separate train and test sets:\n",
    "    train, test = train_test_split(data, test_size=.2, stratify=data[['DX_FINAL_2.0', 'DX_FINAL_3.0']],\n",
    "                                  random_state= 42)\n",
    "\n",
    "    #separate out the response variables: \n",
    "    X_train =  train.drop(to_drop, axis=1)\n",
    "    y_train = train[['DX_FINAL_2.0', 'DX_FINAL_3.0']]\n",
    "    X_test = test.drop(to_drop, axis=1)\n",
    "    y_test = test[['DX_FINAL_2.0', 'DX_FINAL_3.0']]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30pc, y_train_30pc, X_test_30pc, y_test_30pc = prepare_data(data_after_impute_30pc, to_drop)\n",
    "X_train_50pc, y_train_50pc, X_test_50pc, y_test_50pc = prepare_data(data_after_impute_50pc, to_drop)\n",
    "X_train_100pc, y_train_100pc, X_test_100pc, y_test_100pc = prepare_data(data_after_impute_100pc, to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_100pc.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use cross validation to choose the appropriate hyperparameters for our random forest model. There are three hyperparameters that need to be tuned. \n",
    "1. max_depth \n",
    "2. number_estimators\n",
    "3. max_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a function to do manual selection of hyperparameters by iterating through a range of parameters.\n",
    "# alternatively this can be done with grid searchcv. \n",
    "\n",
    "def choose_hyper_parameters(X_train, y_train):\n",
    "    best_score = 0\n",
    "    k_fold=5\n",
    "    best_max_depth = 0\n",
    "    best_max_features = 0\n",
    "    best_n_trees = 0\n",
    "    \n",
    "    max_depth =500 #maximum depth of the tree\n",
    "    max_features = [5, 10, 20, 30, 40, 60, 70, 90, 125, X_train.shape[1]] #number of features considered at each split \n",
    "    n_trees = [5, 10, 20, 30, 50, 100, 500, 1000] #combine n_trees. \n",
    "    \n",
    "    for t in n_trees:\n",
    "        for f in max_features:\n",
    "            for d in range(1, max_depth, 25):\n",
    "                \n",
    "                rf_model = RandomForestClassifier(n_estimators=t, max_features= f, max_depth= d, random_state=42)\n",
    "                \n",
    "                #cross validation score: \n",
    "                scores = cross_val_score(rf_model, X_train, y_train, cv=k_fold, scoring = 'accuracy')\n",
    "                #compute mean \n",
    "                mean_score = np.mean(scores)\n",
    "                \n",
    "                #check if the core is better than current best score and if so store parameters:\n",
    "                if mean_score>best_score:\n",
    "                    best_score = mean_score\n",
    "                    best_max_depth = d\n",
    "                    best_max_features = f\n",
    "                    best_n_trees = t\n",
    "                    \n",
    "                #print ('Best score: ', best_score, 'best_max_d: ', best_max_depth, \n",
    "                      'best_n_trees: ', best_n_trees, 'best_max_features: ', best_max_features)\n",
    "                #print('curr score: ', mean_score, 'curr_max_d: ', d, 'curr_n_trees: ', t, 'curr_max_features: ', f)\n",
    "                \n",
    "    return best_max_depth, best_max_features, best_n_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each set we will need to choose its own set of hyperparameters. \n",
    "max_depth_30pc, max_features_30pc, num_trees_30pc = choose_hyper_parameters(X_train_30pc, y_train_30pc)\n",
    "max_depth_50pc, max_features_50pc, num_trees_50pc = choose_hyper_parameters(X_train_50pc, y_train_50pc)\n",
    "max_depth_100pc, max_features_100pc, num_trees_100pc = choose_hyper_parameters(X_train_100pc, y_train_100pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gridsearch CV and randomized CV to see if we get similar results with both hyperparamter search tools\n",
    "def perform_parameter_search(X_train, y_train):\n",
    "    param_grid = {\"max_depth\": [3, None],\n",
    "                  \"max_features\": [5, 10, 20, 30, 40, 60, 70, 90, 125, X_train.shape[1]],\n",
    "                  \"min_samples_split\": [3, 5, 7, 10, 20, 30, 100],\n",
    "                  \"bootstrap\": [True],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "    # run grid search\n",
    "    rf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "    grid_search = GridSearchCV(rf, param_grid=param_grid, cv=5)\n",
    "    #start = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_30pc_model = perform_parameter_search(X_train_30pc, y_train_30pc)\n",
    "grid_search_50pc_model = perform_parameter_search(X_train_50pc, y_train_50pc)\n",
    "grid_search_100pc_model = perform_parameter_search(X_train_100pc, y_train_100pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=11, max_features=70, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Here are the chosen hyperparameters based on the searching the above mentioned parameters\n",
    "\n",
    "max_depth_30pc, max_features_30pc, num_trees_30pc= 11, 40, 200\n",
    "max_depth_50pc, max_features_50pc, num_trees_50pc = 11, 50, 200#11, 40, 200\n",
    "max_depth_100pc, max_features_100pc, num_trees_100pc = 11, 70, 200\n",
    "\n",
    "rf_model_30pc = RandomForestClassifier(n_estimators=num_trees_30pc, max_depth=max_depth_30pc, \n",
    "                                  max_features = max_features_30pc, random_state=42)\n",
    "rf_model_30pc.fit(X_train_30pc, y_train_30pc)\n",
    "\n",
    "\n",
    "rf_model_50pc = RandomForestClassifier(n_estimators=num_trees_50pc, max_depth=max_depth_50pc, \n",
    "                                  max_features = max_features_50pc, random_state=42)\n",
    "rf_model_50pc.fit(X_train_50pc, y_train_50pc)\n",
    "\n",
    "rf_model_100pc = RandomForestClassifier(n_estimators=num_trees_100pc, max_depth=max_depth_100pc, \n",
    "                                  max_features = max_features_100pc, random_state=42)\n",
    "rf_model_100pc.fit(X_train_100pc, y_train_100pc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_30pc = accuracy_score(rf_model_30pc.predict(X_train_30pc), y_train_30pc)\n",
    "test_score_30pc = accuracy_score(rf_model_30pc.predict(X_test_30pc), y_test_30pc)\n",
    "\n",
    "\n",
    "train_score_50pc = accuracy_score(rf_model_50pc.predict(X_train_50pc), y_train_50pc)\n",
    "test_score_50pc = accuracy_score(rf_model_50pc.predict(X_test_50pc), y_test_50pc)\n",
    "\n",
    "\n",
    "train_score_100pc = accuracy_score(rf_model_100pc.predict(X_train_100pc), y_train_100pc)\n",
    "test_score_100pc = accuracy_score(rf_model_100pc.predict(X_test_100pc), y_test_100pc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824455205811138 0.7796610169491526\n",
      "0.9842615012106537 0.7966101694915254\n",
      "0.9854721549636803 0.7796610169491526\n"
     ]
    }
   ],
   "source": [
    "print(train_score_30pc, test_score_30pc)\n",
    "print(train_score_50pc, test_score_50pc)\n",
    "print(train_score_100pc, test_score_100pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns a % imputed for each of the new features added in the imputed data by \n",
    "# getting this info from the base columns\n",
    "\n",
    "def order_by_num_imputed(orig_data):\n",
    "    total_patients = orig_data.shape[0]\n",
    "    #compute the sum of nas in each column in original data: \n",
    "    columns = list(orig_data.columns)\n",
    "    relevant_data = orig_data[columns]\n",
    "    num_na = pd.DataFrame((relevant_data.isna().sum()/total_patients)*100)\n",
    "    num_na = num_na.rename(columns={0:'num_na'})\n",
    "    num_na = num_na.to_dict()\n",
    "    num_na = num_na['num_na'] \n",
    "    return num_na\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_na = order_by_num_imputed(data_b4_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this base model, we can order the features by feature importance that is spit out by random forest. We will also combine this with how many of these top features were missing in the original data to get a sense of how many of our very important features in the data come from mostly imputed data. We will start by looking at the top 40 features of each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_important_features(x_train, model):\n",
    "    features = list(x_train.columns)\n",
    "    importances = list(model.feature_importances_)\n",
    "    feature_importance = pd.DataFrame({'Names': features, 'Feature_Importance': importances})\n",
    "    result = feature_importance.sort_values(['Feature_Importance'], ascending= False)\n",
    "    return result\n",
    "\n",
    "def correlate_feature_importance_and_missingness(model, missing_dict, x_train):\n",
    "    \n",
    "    top_features = find_important_features(x_train, model)\n",
    "    top_features = top_features.head(20)\n",
    "    \n",
    "    baseline_cols = pd.read_csv(\"BaselineNames.csv\")\n",
    "    baseline_cols.head()\n",
    "    baseline_cols = baseline_cols.drop('Unnamed: 0', axis = 1)\n",
    "    baseline_cols = baseline_cols.set_index('New Col')\n",
    "    baseline_cols = baseline_cols.to_dict()\n",
    "    baseline_cols = baseline_cols['Base col ']\n",
    "    \n",
    "    nans = []\n",
    "    for i in range(top_features.shape[0]):\n",
    "        column_name = top_features.iloc[i, 1]\n",
    "        base_column = baseline_cols[column_name]\n",
    "        percent_na = num_na[base_column]\n",
    "        nans.append(percent_na)\n",
    "    top_features['percent_na'] = nans\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Importance</th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.127567</td>\n",
       "      <td>mPACCtrailsB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.126507</td>\n",
       "      <td>CDRSB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.070549</td>\n",
       "      <td>mPACCdigit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.057423</td>\n",
       "      <td>LDELTOTAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047498</td>\n",
       "      <td>RID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046246</td>\n",
       "      <td>AV45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.034174</td>\n",
       "      <td>FAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026932</td>\n",
       "      <td>FDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.022497</td>\n",
       "      <td>ADAS13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.013881</td>\n",
       "      <td>RAVLT_immediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012951</td>\n",
       "      <td>ABETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.011337</td>\n",
       "      <td>MidTemp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.010925</td>\n",
       "      <td>Hippocampus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.010130</td>\n",
       "      <td>Entorhinal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.009237</td>\n",
       "      <td>DIGITSCOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.009113</td>\n",
       "      <td>EcogSPTotal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.009089</td>\n",
       "      <td>EcogSPOrgan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.008295</td>\n",
       "      <td>EcogSPMem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007417</td>\n",
       "      <td>PTAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.006970</td>\n",
       "      <td>MOCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.006949</td>\n",
       "      <td>Fusiform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.006500</td>\n",
       "      <td>ADAS11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.006206</td>\n",
       "      <td>HMT16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005942</td>\n",
       "      <td>ADASQ4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.005533</td>\n",
       "      <td>EcogSPLang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.005429</td>\n",
       "      <td>RCT1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.005367</td>\n",
       "      <td>EcogSPPlan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.005341</td>\n",
       "      <td>MH16CSMOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005323</td>\n",
       "      <td>TAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.005307</td>\n",
       "      <td>HMT4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.000182</td>\n",
       "      <td>PTRACCAT_Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.000182</td>\n",
       "      <td>MH11HEMA_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>NXOTHER_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.000178</td>\n",
       "      <td>NXSENSOR_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.000171</td>\n",
       "      <td>NXVISUAL_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.000169</td>\n",
       "      <td>BCPALPIT_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.000164</td>\n",
       "      <td>BCBREATH_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.000152</td>\n",
       "      <td>PTHAND_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.000139</td>\n",
       "      <td>DADAD_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.000132</td>\n",
       "      <td>PTGENDER_Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.000120</td>\n",
       "      <td>BCCRYING_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>PTETHCAT_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>PTRACCAT_More than one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.000098</td>\n",
       "      <td>PTTLANG_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.000097</td>\n",
       "      <td>NXPLANTA_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.000096</td>\n",
       "      <td>NXAUDITO_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.000090</td>\n",
       "      <td>PTMARRY_Never married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.000087</td>\n",
       "      <td>PTRACCAT_Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>MOMAD_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>NXNERVE_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>NXMOTOR_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>PTNOTRT_2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>PTMARRY_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>HMT70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>HMT98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>HMT69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>PTRACCAT_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>HMT93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>PTRACCAT_Hawaiian/Other PI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature_Importance                       Names\n",
       "44             0.127567                mPACCtrailsB\n",
       "8              0.126507                       CDRSB\n",
       "43             0.070549                  mPACCdigit\n",
       "17             0.057423                   LDELTOTAL\n",
       "0              0.047498                         RID\n",
       "4              0.046246                        AV45\n",
       "20             0.034174                         FAQ\n",
       "3              0.026932                         FDG\n",
       "10             0.022497                      ADAS13\n",
       "13             0.013881             RAVLT_immediate\n",
       "5              0.012951                       ABETA\n",
       "41             0.011337                     MidTemp\n",
       "37             0.010925                 Hippocampus\n",
       "39             0.010130                  Entorhinal\n",
       "18             0.009237                   DIGITSCOR\n",
       "35             0.009113                 EcogSPTotal\n",
       "33             0.009089                 EcogSPOrgan\n",
       "29             0.008295                   EcogSPMem\n",
       "7              0.007417                        PTAU\n",
       "21             0.006970                        MOCA\n",
       "40             0.006949                    Fusiform\n",
       "9              0.006500                      ADAS11\n",
       "61             0.006206                       HMT16\n",
       "11             0.005942                      ADASQ4\n",
       "30             0.005533                  EcogSPLang\n",
       "73             0.005429                     RCT1408\n",
       "32             0.005367                  EcogSPPlan\n",
       "101            0.005341                   MH16CSMOK\n",
       "6              0.005323                         TAU\n",
       "51             0.005307                        HMT4\n",
       "..                  ...                         ...\n",
       "138            0.000182              PTRACCAT_Asian\n",
       "169            0.000182                MH11HEMA_1.0\n",
       "172            0.000181                 NXOTHER_2.0\n",
       "133            0.000178                NXSENSOR_2.0\n",
       "167            0.000171                NXVISUAL_2.0\n",
       "115            0.000169                BCPALPIT_2.0\n",
       "118            0.000164                BCBREATH_2.0\n",
       "137            0.000152                  PTHAND_2.0\n",
       "123            0.000139                   DADAD_2.0\n",
       "114            0.000132               PTGENDER_Male\n",
       "168            0.000120                BCCRYING_2.0\n",
       "165            0.000115            PTETHCAT_Unknown\n",
       "141            0.000107      PTRACCAT_More than one\n",
       "135            0.000098                 PTTLANG_2.0\n",
       "125            0.000097                NXPLANTA_2.0\n",
       "174            0.000096                NXAUDITO_2.0\n",
       "161            0.000090       PTMARRY_Never married\n",
       "139            0.000087              PTRACCAT_Black\n",
       "117            0.000083                   MOMAD_2.0\n",
       "159            0.000066                 NXNERVE_2.0\n",
       "126            0.000057                 NXMOTOR_2.0\n",
       "183            0.000028                 PTNOTRT_2.0\n",
       "162            0.000013             PTMARRY_Unknown\n",
       "72             0.000000                       HMT70\n",
       "56             0.000000                       HMT98\n",
       "54             0.000000                       HMT69\n",
       "142            0.000000            PTRACCAT_Unknown\n",
       "45             0.000000                       Month\n",
       "48             0.000000                       HMT93\n",
       "140            0.000000  PTRACCAT_Hawaiian/Other PI\n",
       "\n",
       "[187 rows x 2 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_important_features(X_train_100pc, rf_model_100pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take our most important features and ask which ones have the most missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features_30pc = correlate_feature_importance_and_missingness(rf_model_30pc, missing_dict=num_na, x_train = X_train_30pc)\n",
    "top_features_50pc = correlate_feature_importance_and_missingness(rf_model_50pc, missing_dict=num_na, x_train = X_train_50pc)\n",
    "top_features_100pc = correlate_feature_importance_and_missingness(rf_model_100pc, missing_dict=num_na, x_train = X_train_100pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Importance</th>\n",
       "      <th>Names</th>\n",
       "      <th>percent_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.129998</td>\n",
       "      <td>mPACCtrailsB</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.122935</td>\n",
       "      <td>CDRSB</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.062572</td>\n",
       "      <td>mPACCdigit</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.056198</td>\n",
       "      <td>LDELTOTAL</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051817</td>\n",
       "      <td>RID</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_Importance         Names  percent_na\n",
       "43            0.129998  mPACCtrailsB    0.096852\n",
       "8             0.122935         CDRSB    0.000000\n",
       "42            0.062572    mPACCdigit    0.096852\n",
       "17            0.056198     LDELTOTAL    0.145278\n",
       "0             0.051817           RID    0.000000"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features_50pc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Importance</th>\n",
       "      <th>Names</th>\n",
       "      <th>percent_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132868</td>\n",
       "      <td>CDRSB</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.116929</td>\n",
       "      <td>mPACCtrailsB</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.074955</td>\n",
       "      <td>LDELTOTAL</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.068497</td>\n",
       "      <td>mPACCdigit</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063106</td>\n",
       "      <td>RID</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.049988</td>\n",
       "      <td>FAQ</td>\n",
       "      <td>0.629540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.029734</td>\n",
       "      <td>ADAS13</td>\n",
       "      <td>0.387409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.017198</td>\n",
       "      <td>Hippocampus</td>\n",
       "      <td>19.273608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016192</td>\n",
       "      <td>ADASQ4</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.015210</td>\n",
       "      <td>Entorhinal</td>\n",
       "      <td>21.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.014879</td>\n",
       "      <td>RAVLT_immediate</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.014179</td>\n",
       "      <td>MidTemp</td>\n",
       "      <td>21.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.013215</td>\n",
       "      <td>Fusiform</td>\n",
       "      <td>21.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.011834</td>\n",
       "      <td>MMSCORE</td>\n",
       "      <td>0.048426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.010506</td>\n",
       "      <td>HMT16</td>\n",
       "      <td>25.084746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.009797</td>\n",
       "      <td>HMT15</td>\n",
       "      <td>25.084746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.009690</td>\n",
       "      <td>WholeBrain</td>\n",
       "      <td>16.755448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009241</td>\n",
       "      <td>TRABSCOR</td>\n",
       "      <td>1.259080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.009236</td>\n",
       "      <td>ICV</td>\n",
       "      <td>15.980630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009204</td>\n",
       "      <td>ADAS11</td>\n",
       "      <td>0.290557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_Importance            Names  percent_na\n",
       "3             0.132868            CDRSB    0.000000\n",
       "23            0.116929     mPACCtrailsB    0.096852\n",
       "12            0.074955        LDELTOTAL    0.145278\n",
       "22            0.068497       mPACCdigit    0.096852\n",
       "0             0.063106              RID    0.000000\n",
       "14            0.049988              FAQ    0.629540\n",
       "5             0.029734           ADAS13    0.387409\n",
       "16            0.017198      Hippocampus   19.273608\n",
       "6             0.016192           ADASQ4    0.145278\n",
       "18            0.015210       Entorhinal   21.549637\n",
       "8             0.014879  RAVLT_immediate    0.145278\n",
       "20            0.014179          MidTemp   21.549637\n",
       "19            0.013215         Fusiform   21.549637\n",
       "65            0.011834          MMSCORE    0.048426\n",
       "35            0.010506            HMT16   25.084746\n",
       "49            0.009797            HMT15   25.084746\n",
       "17            0.009690       WholeBrain   16.755448\n",
       "13            0.009241         TRABSCOR    1.259080\n",
       "21            0.009236              ICV   15.980630\n",
       "4             0.009204           ADAS11    0.290557"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features_30pc.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Importance</th>\n",
       "      <th>Names</th>\n",
       "      <th>percent_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.127567</td>\n",
       "      <td>mPACCtrailsB</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.126507</td>\n",
       "      <td>CDRSB</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.070549</td>\n",
       "      <td>mPACCdigit</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.057423</td>\n",
       "      <td>LDELTOTAL</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047498</td>\n",
       "      <td>RID</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046246</td>\n",
       "      <td>AV45</td>\n",
       "      <td>46.295400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.034174</td>\n",
       "      <td>FAQ</td>\n",
       "      <td>0.629540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026932</td>\n",
       "      <td>FDG</td>\n",
       "      <td>31.138015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.022497</td>\n",
       "      <td>ADAS13</td>\n",
       "      <td>0.387409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.013881</td>\n",
       "      <td>RAVLT_immediate</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012951</td>\n",
       "      <td>ABETA</td>\n",
       "      <td>39.515738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.011337</td>\n",
       "      <td>MidTemp</td>\n",
       "      <td>21.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.010925</td>\n",
       "      <td>Hippocampus</td>\n",
       "      <td>19.273608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.010130</td>\n",
       "      <td>Entorhinal</td>\n",
       "      <td>21.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.009237</td>\n",
       "      <td>DIGITSCOR</td>\n",
       "      <td>60.435835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.009113</td>\n",
       "      <td>EcogSPTotal</td>\n",
       "      <td>31.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.009089</td>\n",
       "      <td>EcogSPOrgan</td>\n",
       "      <td>32.445521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.008295</td>\n",
       "      <td>EcogSPMem</td>\n",
       "      <td>31.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007417</td>\n",
       "      <td>PTAU</td>\n",
       "      <td>39.515738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.006970</td>\n",
       "      <td>MOCA</td>\n",
       "      <td>31.331719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_Importance            Names  percent_na\n",
       "44            0.127567     mPACCtrailsB    0.096852\n",
       "8             0.126507            CDRSB    0.000000\n",
       "43            0.070549       mPACCdigit    0.096852\n",
       "17            0.057423        LDELTOTAL    0.145278\n",
       "0             0.047498              RID    0.000000\n",
       "4             0.046246             AV45   46.295400\n",
       "20            0.034174              FAQ    0.629540\n",
       "3             0.026932              FDG   31.138015\n",
       "10            0.022497           ADAS13    0.387409\n",
       "13            0.013881  RAVLT_immediate    0.145278\n",
       "5             0.012951            ABETA   39.515738\n",
       "41            0.011337          MidTemp   21.549637\n",
       "37            0.010925      Hippocampus   19.273608\n",
       "39            0.010130       Entorhinal   21.549637\n",
       "18            0.009237        DIGITSCOR   60.435835\n",
       "35            0.009113      EcogSPTotal   31.428571\n",
       "33            0.009089      EcogSPOrgan   32.445521\n",
       "29            0.008295        EcogSPMem   31.428571\n",
       "7             0.007417             PTAU   39.515738\n",
       "21            0.006970             MOCA   31.331719"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features_100pc.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'percent missing')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a20da3048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (7,6))\n",
    "plt.scatter(x=top_features_30pc[\"Feature_Importance\"], y=top_features_30pc[\"percent_na\"])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('percent missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'percent missing')"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2366a5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (7,6))\n",
    "plt.scatter(x=top_features_50pc[\"Feature_Importance\"], y=top_features_50pc[\"percent_na\"])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('percent missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'percent missing')"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a20da3400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (7,6))\n",
    "plt.scatter(x=top_features_100pc[\"Feature_Importance\"], y=top_features_100pc[\"percent_na\"])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('percent missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_cs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
