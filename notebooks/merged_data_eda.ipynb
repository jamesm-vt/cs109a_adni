{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADNI Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table {\n",
       "        display: inline-block\n",
       "    }\n",
       "    .rendered_html td, .rendered_html th {text-align: left;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open(\"./project.css\") as css:\n",
    "    styles = css.read()\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADNI\n",
    "\n",
    "The overarching goal of the Alzheimer's Disease Neuroimaging Initiative (ADNI) is to identify biomarkers of Alzheimer’s disease. Specifically the study aims at identifying those biomarkers that can be used in the earliest (pre-dementia) prediction of Alzheimer's Disease (AD). The study began in 2004, a time when biomarkers for Alzheimer’s disease which could be used for diagnostics in pre-dementia individuals were virtually unknown. There are four categories of biomarkers in the scope of the initiative: (clinical, imaging, genetic, and biochemical).\n",
    "\n",
    "There have been ADNI 4 study phases to date with the following goals:\n",
    "\n",
    "<!-- Begin ADNI Phase table -->\n",
    "\n",
    "| Study Phase | Goal | Dates | Cohort |\n",
    "|:---: |:--- |:--- | --- |\n",
    "| ADNI 1 | Develop biomarkers as outcome measures for clinical trials | 2004-2009 | 200 elderly controls<br>400 MCI<br>200 AD |\n",
    "| ADNI GO | Examine biomarkers in earlier stages of disease | 2009-2011 | Existing ADNI-1 +<br>200 early MCI |\n",
    "| ADNI 2 | Develop biomarkers as predictors of cognitive decline, and as outcome measures | 2011-2016 | Existing ADNI-1 and ADNI-GO +<br>150 elderly controls<br>100 early MCI<br>150 late MCI<br>150 AD |\n",
    "| ADNI 3 | Study the use of tau PET and functional imaging techniques in clinical trials | 2016 - present | Existing ADNI-1, ADNI-GO, ADNI-2 +<br>133 elderly controls<br>151 MCI<br>87 AD |\n",
    "\n",
    "<!-- End ADNI phase table -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADNI Data\n",
    "Before looking at a single observation or feature, there is a lot of information we can glean from reviewing ADNI metadata. There are over 250 datasets in the ADNI data inventory spanning the 4 study phases (ADNI 1, GO, 2, 3) - and this number does not include the archives. These studies are longitudinal. ADNI-1 started in 2004 and ADNI-3 continues today. Although there is potentially a wealth of information, insights, and predictive power in these data, their data collection methods and longitudinal nature present many challenges.\n",
    "\n",
    "One challenge is that all biometrics within the scope of the study are not collected across all study phases. Also, within each phase, not all participants had all measurements taken. For example, in ADNI-1, $100\\%$ of the cohort had a 1.5 Tesla (1.5T) MRI, $50\\%$ had a PET scan. Of the $50\\%$ that didn't have a PET scan, $25\\%$ had a 3T MRI. Finally, only $20\\%$ of the ADNI-1 cohort had a lumbar puncture (L.P.) to collect cerebral spinal fluid (CSF).\n",
    "\n",
    "Other data challenges are related to the longitudinal nature of the studies across the different phases. In each successive phase of the study, participants were rolled over from previous phases while new participants were also added - *(cohort details can be seen in the table above)*. However, existing participants in the study must provide their consent to be included in each subsequent phase. Furthermore, an obvious, but nonetheless real, complication with this population is that a participant could be removed from the study at any time due to significant deterioration in health or death. \n",
    "\n",
    "The result is that each phase of the study produces a richer set of longitudinal data than the previous study because of the rollover participants. The downside of this design is the inherent introduction of missingness into the data due to the recently joined participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An initial look at the data.\n",
    "Given the breadth of available data and the challenges mentioned above, deciding what data to use to start EDA is a non-trivial task. Fortunately, there is a combined dataset available consisting of key ADNI tables merged into a single table based on the patient identifier or `RID`. As is common with most ADNI datasets, each observation represents a single visit for a participant. This means that a single participant (`RID`) may appear multiple times in the dataset. The number of occurrences will generally depend on what phase the participant entered the study.\n",
    "\n",
    "Let's take an initial look at the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconda config --add channels conda-forge\\nconda install -y mlxtend\\nconda update -y pandas\\nconda update -y numpy\\nconda update -y scikit-learn --no-channel-priority\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ADNI_utilities as utils\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "### Stacking libraries require mlxtend\n",
    "### conda install mlxtend --channel conda-forge\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "# Use the following to install mlxtend and to\n",
    "# update other libs to required (latest) versions\n",
    "\"\"\"\n",
    "conda config --add channels conda-forge\n",
    "conda install -y mlxtend\n",
    "conda update -y pandas\n",
    "conda update -y numpy\n",
    "conda update -y scikit-learn --no-channel-priority\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni_merge = pd.read_csv('../data/ADNIMERGE.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is (13632, 113).\n",
      "There are 2081 unique participants in the dataset.\n",
      "There is an average of 6.55 rows in the data per participant.\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the dataset is {}.\".format(adni_merge.shape))\n",
    "print(\"There are {} unique participants in the dataset.\"\n",
    "      .format(len(adni_merge.RID.unique())))\n",
    "print(\"There is an average of {:.2f} rows in the data per participant.\"\n",
    "      .format(len(adni_merge)/len(adni_merge.RID.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the dataset contains $2081$ unique study participants spanning $13632$ visits. The data is longitudinal based on participant visits spaced roughly six months apart. The `VISCODE` feature represents the visit in which the measurements and evaluations were captured. The initial evaluation measurements are identified by `VISCODE` = `'bl'`, which stands for baseline. Below are the unique `VISCODE` values in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bl', 'm03', 'm06', 'm12', 'm18', 'm24', 'm36', 'm30', 'm42',\n",
       "       'm48', 'm54', 'm60', 'm66', 'm72', 'm78', 'm84', 'm90', 'm96',\n",
       "       'm102', 'm108', 'm114', 'm120', 'm126', 'm132', 'm144', 'm156'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adni_merge.sort_values(by='Month')['VISCODE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the number of study participants per `VISCODE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M represents months since the last visit (0 = baseline/initial visit)\n",
    "adni_by_month = adni_merge.groupby(by='M').count()\n",
    "particpants = adni_by_month['RID']\n",
    "visits = adni_merge.sort_values(by='M')['VISCODE'].unique()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,8))\n",
    "\n",
    "ax.set_title('Number of participants per visit', size=17)\n",
    "ax.set_xticks(range(0, 26, 2))\n",
    "ax.set_xlabel('Visit Code (indicates months since inital baseline visit)', size=14)\n",
    "ax.set_ylabel('Participants', size=14)\n",
    "ax.bar(visits, particpants)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the design of the study as discussed above, we expect there to be a lot of missing data in this data set. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 507270 missing values.\n",
      "Out of 113 features in the dataset, 93 have missing values.\n",
      "\n",
      "Quartiles of missing data:\n",
      "      Num Missing  Pct. Missing\n",
      "0.25       3839.0     28.161678\n",
      "0.50       6185.0     45.371185\n",
      "0.75       7758.0     56.910211\n",
      "1.00      13632.0    100.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Missing</th>\n",
       "      <th>Pct. Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FLDSTRENG_bl</th>\n",
       "      <td>13632.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLDSTRENG</th>\n",
       "      <td>13632.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIB_bl</th>\n",
       "      <td>13483.0</td>\n",
       "      <td>98.906984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIB</th>\n",
       "      <td>13409.0</td>\n",
       "      <td>98.364143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTAU</th>\n",
       "      <td>11262.0</td>\n",
       "      <td>82.614437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABETA</th>\n",
       "      <td>11261.0</td>\n",
       "      <td>82.607101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAU</th>\n",
       "      <td>11261.0</td>\n",
       "      <td>82.607101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AV45</th>\n",
       "      <td>11122.0</td>\n",
       "      <td>81.587441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDG</th>\n",
       "      <td>10125.0</td>\n",
       "      <td>74.273768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIGITSCOR</th>\n",
       "      <td>9832.0</td>\n",
       "      <td>72.124413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Num Missing  Pct. Missing\n",
       "FLDSTRENG_bl      13632.0    100.000000\n",
       "FLDSTRENG         13632.0    100.000000\n",
       "PIB_bl            13483.0     98.906984\n",
       "PIB               13409.0     98.364143\n",
       "PTAU              11262.0     82.614437\n",
       "ABETA             11261.0     82.607101\n",
       "TAU               11261.0     82.607101\n",
       "AV45              11122.0     81.587441\n",
       "FDG               10125.0     74.273768\n",
       "DIGITSCOR          9832.0     72.124413"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate missing data\n",
    "missing_data = utils.calculate_missing_data(adni_merge)\n",
    "\n",
    "# Look at the top 10 columns in terms of missing values\n",
    "missing_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've noticed that the numbers of non-null values for `PTAU`, `ABETA`, and `TAU` are suspiciously close to the number of unique participants. The fact that these features all have almost the exact same number of missing values could be an artifact of how and when these data were collected. Perhaps these were collected on the initial baseline `bl` visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Missing</th>\n",
       "      <th>Pct. Missing</th>\n",
       "      <th>Num Values Present</th>\n",
       "      <th>Num Participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TAU</th>\n",
       "      <td>11261.0</td>\n",
       "      <td>82.607101</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTAU</th>\n",
       "      <td>11262.0</td>\n",
       "      <td>82.614437</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABETA</th>\n",
       "      <td>11261.0</td>\n",
       "      <td>82.607101</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Num Missing  Pct. Missing  Num Values Present  Num Participants\n",
       "TAU        11261.0     82.607101              2371.0              2081\n",
       "PTAU       11262.0     82.614437              2370.0              2081\n",
       "ABETA      11261.0     82.607101              2371.0              2081"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_proteins = missing_data.loc[['TAU', 'PTAU', 'ABETA']]\n",
    "missing_proteins['Num Values Present'] = len(adni_merge) - missing_proteins['Num Missing']\n",
    "missing_proteins['Num Participants'] = len(adni_merge.RID.unique())\n",
    "missing_proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many options to deal with the variable number of visits in the merged data set. Instead of vertically stacking the visits as in the merged dataset, we could split on `VISCODE` and stack the data *horizontally* creating wide rows with many more features. However, this is essentially transposing the data and moving the missing values from deep columns to wide rows. Another option is to split the data into multiple subsets of data based on `VISCODE` and deal with them separately. As shown in the \"*Participants per visit*\" figure, every participant had at least a baseline visit. This subset should provide the most complete and uniform representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the baseline visit subset:  (2081, 113)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>PTID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>SITE</th>\n",
       "      <th>COLPROT</th>\n",
       "      <th>ORIGPROT</th>\n",
       "      <th>EXAMDATE</th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>...</th>\n",
       "      <th>TAU_bl</th>\n",
       "      <th>PTAU_bl</th>\n",
       "      <th>FDG_bl</th>\n",
       "      <th>PIB_bl</th>\n",
       "      <th>AV45_bl</th>\n",
       "      <th>Years_bl</th>\n",
       "      <th>Month_bl</th>\n",
       "      <th>Month</th>\n",
       "      <th>M</th>\n",
       "      <th>update_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>bl</td>\n",
       "      <td>11</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2005-09-08</td>\n",
       "      <td>CN</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.36665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-19 22:51:15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>bl</td>\n",
       "      <td>11</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>239.7</td>\n",
       "      <td>22.83</td>\n",
       "      <td>1.08355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-19 22:51:15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>022_S_0004</td>\n",
       "      <td>bl</td>\n",
       "      <td>22</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2005-11-08</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>67.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>153.1</td>\n",
       "      <td>13.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-19 22:51:15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>011_S_0005</td>\n",
       "      <td>bl</td>\n",
       "      <td>11</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2005-09-07</td>\n",
       "      <td>CN</td>\n",
       "      <td>73.7</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>337</td>\n",
       "      <td>33.43</td>\n",
       "      <td>1.29343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-19 22:51:15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>100_S_0006</td>\n",
       "      <td>bl</td>\n",
       "      <td>100</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2005-11-29</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>80.4</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-19 22:51:15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RID        PTID VISCODE  SITE COLPROT ORIGPROT    EXAMDATE DX_bl   AGE  \\\n",
       "0     2  011_S_0002      bl    11   ADNI1    ADNI1  2005-09-08    CN  74.3   \n",
       "1     3  011_S_0003      bl    11   ADNI1    ADNI1  2005-09-12    AD  81.3   \n",
       "5     4  022_S_0004      bl    22   ADNI1    ADNI1  2005-11-08  LMCI  67.5   \n",
       "10    5  011_S_0005      bl    11   ADNI1    ADNI1  2005-09-07    CN  73.7   \n",
       "15    6  100_S_0006      bl   100   ADNI1    ADNI1  2005-11-29  LMCI  80.4   \n",
       "\n",
       "   PTGENDER          ...            TAU_bl PTAU_bl   FDG_bl PIB_bl  AV45_bl  \\\n",
       "0      Male          ...               NaN     NaN  1.36665    NaN      NaN   \n",
       "1      Male          ...             239.7   22.83  1.08355    NaN      NaN   \n",
       "5      Male          ...             153.1   13.29      NaN    NaN      NaN   \n",
       "10     Male          ...               337   33.43  1.29343    NaN      NaN   \n",
       "15   Female          ...               NaN     NaN      NaN    NaN      NaN   \n",
       "\n",
       "    Years_bl  Month_bl  Month  M           update_stamp  \n",
       "0        0.0       0.0      0  0  2018-10-19 22:51:15.0  \n",
       "1        0.0       0.0      0  0  2018-10-19 22:51:15.0  \n",
       "5        0.0       0.0      0  0  2018-10-19 22:51:15.0  \n",
       "10       0.0       0.0      0  0  2018-10-19 22:51:15.0  \n",
       "15       0.0       0.0      0  0  2018-10-19 22:51:15.0  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = adni_merge[adni_merge['VISCODE'] == 'bl'].copy()\n",
    "print('Shape of the baseline visit subset: ', baseline.shape)\n",
    "\n",
    "baseline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examime the missing data from the baseline visit dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 54057 missing values.\n",
      "Out of 113 features in the dataset, 91 have missing values.\n",
      "\n",
      "Quartiles of missing data:\n",
      "      Num Missing  Pct. Missing\n",
      "0.25         22.0      1.057184\n",
      "0.50        728.0     34.983181\n",
      "0.75        851.0     40.893801\n",
      "1.00       2081.0    100.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate missing data\n",
    "missing_data = utils.calculate_missing_data(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in Missing Data\n",
    "Based on the study data, we know that not all biometrics are measured at every visit. Therefore we may be able to pull measures together from different visits to help fill in missing data. Of course since we're dealing with longitudinal data with visits month or years apart, we have to make sure that we only consider measures from visits where the diagnosis code is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching...\n",
      "Updated 4104 of 54057 missing values.\n"
     ]
    }
   ],
   "source": [
    "# For every column in the baseline (VISCODE='bl') with missing values, look for\n",
    "# a value in subsequent visits with the constraint that the DX code must\n",
    "# not have changed. Take the first (earliest) biometric measure available.\n",
    "\n",
    "baseline.sort_values(by='RID')\n",
    "missing_cols = baseline.columns[baseline.isnull().any()]\n",
    "viscodes = list(adni_merge.sort_values(by='Month')['VISCODE'].unique())\n",
    "viscodes.pop(0) # Get rid of 'bl'\n",
    "\n",
    "missing_values = baseline.isnull().sum().sum()\n",
    "updated_values = 0\n",
    "\n",
    "print('Searching...')\n",
    "for col in missing_cols:\n",
    "    \n",
    "    for v in viscodes:\n",
    "        \n",
    "        # Get the RIDs with missing values in this colummn.\n",
    "        # Do this for each VISCODE since we are iteratively\n",
    "        # updating missing values.\n",
    "        rids = baseline[baseline[col].isnull()].RID\n",
    "        \n",
    "        # Create a DataFrame from adni_merge for the current\n",
    "        # VISCODE, RIDs, & where current col is not null.\n",
    "        df = adni_merge.loc[(adni_merge.RID.isin(rids))\n",
    "                            & (adni_merge.VISCODE == v)\n",
    "                            & (adni_merge[col].notnull()),\n",
    "                            baseline.columns] \n",
    "               \n",
    "        if df.empty: # if no matches, continue\n",
    "            continue\n",
    "            \n",
    "        df = df.copy()\n",
    "        df.sort_values(by='RID', inplace=True)\n",
    "            \n",
    "        # Find baseline participants who are also in the current VISCODE\n",
    "        bl = baseline[baseline.RID.isin(df.RID)].copy()\n",
    "        bl.sort_values(by='RID', inplace=True)\n",
    "        df.index = bl.index\n",
    "        \n",
    "        # Only keep those where the diagnosis is unchanged & col is not null\n",
    "        df = df[(df.DX == bl.DX) & (df[col].notnull())]\n",
    "\n",
    "        if df.empty:  # if DX codes don't match, continue\n",
    "            continue\n",
    "\n",
    "        # Update null values in the original baseline DF\n",
    "        baseline.loc[baseline.index.isin(df.index), col] = df[col]\n",
    "        updated_values += len(df)\n",
    "\n",
    "print(f'Updated {updated_values} of {missing_values} missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 49953 missing values.\n",
      "Out of 113 features in the dataset, 91 have missing values.\n",
      "\n",
      "Quartiles of missing data:\n",
      "      Num Missing  Pct. Missing\n",
      "0.25         21.0      1.009130\n",
      "0.50        641.0     30.802499\n",
      "0.75        832.0     39.980778\n",
      "1.00       2081.0    100.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Missing</th>\n",
       "      <th>Pct. Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FLDSTRENG</th>\n",
       "      <td>2081.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLDSTRENG_bl</th>\n",
       "      <td>2081.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIB_bl</th>\n",
       "      <td>2061.0</td>\n",
       "      <td>99.038924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIB</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>95.627102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIGITSCOR_bl</th>\n",
       "      <td>1267.0</td>\n",
       "      <td>60.884190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIGITSCOR</th>\n",
       "      <td>1264.0</td>\n",
       "      <td>60.740029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AV45_bl</th>\n",
       "      <td>1107.0</td>\n",
       "      <td>53.195579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AV45</th>\n",
       "      <td>971.0</td>\n",
       "      <td>46.660259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogSPOrgan_bl</th>\n",
       "      <td>891.0</td>\n",
       "      <td>42.815954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTAU_bl</th>\n",
       "      <td>866.0</td>\n",
       "      <td>41.614608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Num Missing  Pct. Missing\n",
       "FLDSTRENG            2081.0    100.000000\n",
       "FLDSTRENG_bl         2081.0    100.000000\n",
       "PIB_bl               2061.0     99.038924\n",
       "PIB                  1990.0     95.627102\n",
       "DIGITSCOR_bl         1267.0     60.884190\n",
       "DIGITSCOR            1264.0     60.740029\n",
       "AV45_bl              1107.0     53.195579\n",
       "AV45                  971.0     46.660259\n",
       "EcogSPOrgan_bl        891.0     42.815954\n",
       "PTAU_bl               866.0     41.614608"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate missing data\n",
    "missing_data = utils.calculate_missing_data(baseline)\n",
    "\n",
    "# Look at the top 10 columns in terms of missing values\n",
    "missing_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly a lot of missing data remain and we will likely have to explore methods to impute these values. Before doing that however, we will explore the data a little closer to see if there are features that should be dropped due to high correlation, lack of information, or other reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FLDSTRENG` and `FLDSTRENG_bl` are providing absolutely no information so we can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.drop(labels=['FLDSTRENG', 'FLDSTRENG_bl'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a lot of features with similar, if not identical, information such as `TAU`, `TAU_bl`, `AV45`, `AV45_bl`. Let's examine this pattern to see if these pairs are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline column</th>\n",
       "      <th>Alternate column</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDRSB_bl</td>\n",
       "      <td>CDRSB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAS11_bl</td>\n",
       "      <td>ADAS11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADAS13_bl</td>\n",
       "      <td>ADAS13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADASQ4_bl</td>\n",
       "      <td>ADASQ4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMSE_bl</td>\n",
       "      <td>MMSE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RAVLT_immediate_bl</td>\n",
       "      <td>RAVLT_immediate</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RAVLT_learning_bl</td>\n",
       "      <td>RAVLT_learning</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RAVLT_forgetting_bl</td>\n",
       "      <td>RAVLT_forgetting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAVLT_perc_forgetting_bl</td>\n",
       "      <td>RAVLT_perc_forgetting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LDELTOTAL_BL</td>\n",
       "      <td>LDELTOTAL</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DIGITSCOR_bl</td>\n",
       "      <td>DIGITSCOR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRABSCOR_bl</td>\n",
       "      <td>TRABSCOR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FAQ_bl</td>\n",
       "      <td>FAQ</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mPACCdigit_bl</td>\n",
       "      <td>mPACCdigit</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mPACCtrailsB_bl</td>\n",
       "      <td>mPACCtrailsB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ventricles_bl</td>\n",
       "      <td>Ventricles</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hippocampus_bl</td>\n",
       "      <td>Hippocampus</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WholeBrain_bl</td>\n",
       "      <td>WholeBrain</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Entorhinal_bl</td>\n",
       "      <td>Entorhinal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fusiform_bl</td>\n",
       "      <td>Fusiform</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MidTemp_bl</td>\n",
       "      <td>MidTemp</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ICV_bl</td>\n",
       "      <td>ICV</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MOCA_bl</td>\n",
       "      <td>MOCA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EcogPtMem_bl</td>\n",
       "      <td>EcogPtMem</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EcogPtLang_bl</td>\n",
       "      <td>EcogPtLang</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EcogPtVisspat_bl</td>\n",
       "      <td>EcogPtVisspat</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EcogPtPlan_bl</td>\n",
       "      <td>EcogPtPlan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EcogPtOrgan_bl</td>\n",
       "      <td>EcogPtOrgan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EcogPtDivatt_bl</td>\n",
       "      <td>EcogPtDivatt</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EcogPtTotal_bl</td>\n",
       "      <td>EcogPtTotal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>EcogSPMem_bl</td>\n",
       "      <td>EcogSPMem</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>EcogSPLang_bl</td>\n",
       "      <td>EcogSPLang</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>EcogSPVisspat_bl</td>\n",
       "      <td>EcogSPVisspat</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>EcogSPPlan_bl</td>\n",
       "      <td>EcogSPPlan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>EcogSPOrgan_bl</td>\n",
       "      <td>EcogSPOrgan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EcogSPDivatt_bl</td>\n",
       "      <td>EcogSPDivatt</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>EcogSPTotal_bl</td>\n",
       "      <td>EcogSPTotal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FDG_bl</td>\n",
       "      <td>FDG</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PIB_bl</td>\n",
       "      <td>PIB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AV45_bl</td>\n",
       "      <td>AV45</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Baseline column       Alternate column  Correlation\n",
       "0                   CDRSB_bl                  CDRSB          1.0\n",
       "1                  ADAS11_bl                 ADAS11          1.0\n",
       "2                  ADAS13_bl                 ADAS13          1.0\n",
       "3                  ADASQ4_bl                 ADASQ4          1.0\n",
       "4                    MMSE_bl                   MMSE          1.0\n",
       "5         RAVLT_immediate_bl        RAVLT_immediate          1.0\n",
       "6          RAVLT_learning_bl         RAVLT_learning          1.0\n",
       "7        RAVLT_forgetting_bl       RAVLT_forgetting          1.0\n",
       "8   RAVLT_perc_forgetting_bl  RAVLT_perc_forgetting          1.0\n",
       "9               LDELTOTAL_BL              LDELTOTAL          1.0\n",
       "10              DIGITSCOR_bl              DIGITSCOR          1.0\n",
       "11               TRABSCOR_bl               TRABSCOR          1.0\n",
       "12                    FAQ_bl                    FAQ          1.0\n",
       "13             mPACCdigit_bl             mPACCdigit          1.0\n",
       "14           mPACCtrailsB_bl           mPACCtrailsB          1.0\n",
       "15             Ventricles_bl             Ventricles          1.0\n",
       "16            Hippocampus_bl            Hippocampus          1.0\n",
       "17             WholeBrain_bl             WholeBrain          1.0\n",
       "18             Entorhinal_bl             Entorhinal          1.0\n",
       "19               Fusiform_bl               Fusiform          1.0\n",
       "20                MidTemp_bl                MidTemp          1.0\n",
       "21                    ICV_bl                    ICV          1.0\n",
       "22                   MOCA_bl                   MOCA          1.0\n",
       "23              EcogPtMem_bl              EcogPtMem          1.0\n",
       "24             EcogPtLang_bl             EcogPtLang          1.0\n",
       "25          EcogPtVisspat_bl          EcogPtVisspat          1.0\n",
       "26             EcogPtPlan_bl             EcogPtPlan          1.0\n",
       "27            EcogPtOrgan_bl            EcogPtOrgan          1.0\n",
       "28           EcogPtDivatt_bl           EcogPtDivatt          1.0\n",
       "29            EcogPtTotal_bl            EcogPtTotal          1.0\n",
       "30              EcogSPMem_bl              EcogSPMem          1.0\n",
       "31             EcogSPLang_bl             EcogSPLang          1.0\n",
       "32          EcogSPVisspat_bl          EcogSPVisspat          1.0\n",
       "33             EcogSPPlan_bl             EcogSPPlan          1.0\n",
       "34            EcogSPOrgan_bl            EcogSPOrgan          1.0\n",
       "35           EcogSPDivatt_bl           EcogSPDivatt          1.0\n",
       "36            EcogSPTotal_bl            EcogSPTotal          1.0\n",
       "37                    FDG_bl                    FDG          1.0\n",
       "38                    PIB_bl                    PIB          1.0\n",
       "39                   AV45_bl                   AV45          1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a correlation matrix of xxx_bl vs xxx\n",
    "corr_df = baseline.corr()\n",
    "cols = baseline.columns\n",
    "col1, col2, corr = [], [], []\n",
    "\n",
    "# Specifically check the correlation of xxx_bl to xxx\n",
    "for col in cols:\n",
    "    if '_bl' in col.lower(): \n",
    "        drop_bl = col[0:-3]\n",
    "        if (drop_bl in cols):\n",
    "            if (col in corr_df.index and corr_df.loc[col][drop_bl] > .8):\n",
    "                col1.append(col)\n",
    "                col2.append(drop_bl)\n",
    "                corr.append(corr_df.loc[col][drop_bl])\n",
    "\n",
    "# Display the results                \n",
    "bl_corr_df = pd.DataFrame({\"Baseline column\": col1, 'Alternate column': col2, \"Correlation\": corr})\n",
    "bl_corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features indeed contain duplicate information so we can drop one of each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape of the baseline subset is (2081, 71).\n"
     ]
    }
   ],
   "source": [
    "baseline = baseline.drop(labels=bl_corr_df['Baseline column'].values, axis=1)\n",
    "print(\"The new shape of the baseline subset is {}.\".format(baseline.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ABETA', 'ABETA_bl', 'ADAS11', 'ADAS13', 'ADASQ4', 'AGE', 'APOE4',\n",
       "       'AV45', 'CDRSB', 'COLPROT', 'DIGITSCOR', 'DX', 'DX_bl', 'EXAMDATE',\n",
       "       'EXAMDATE_bl', 'EcogPtDivatt', 'EcogPtLang', 'EcogPtMem', 'EcogPtOrgan',\n",
       "       'EcogPtPlan', 'EcogPtTotal', 'EcogPtVisspat', 'EcogSPDivatt',\n",
       "       'EcogSPLang', 'EcogSPMem', 'EcogSPOrgan', 'EcogSPPlan', 'EcogSPTotal',\n",
       "       'EcogSPVisspat', 'Entorhinal', 'FAQ', 'FDG', 'FSVERSION',\n",
       "       'FSVERSION_bl', 'Fusiform', 'Hippocampus', 'ICV', 'IMAGEUID',\n",
       "       'LDELTOTAL', 'M', 'MMSE', 'MOCA', 'MidTemp', 'Month', 'Month_bl',\n",
       "       'ORIGPROT', 'PIB', 'PTAU', 'PTAU_bl', 'PTEDUCAT', 'PTETHCAT',\n",
       "       'PTGENDER', 'PTID', 'PTMARRY', 'PTRACCAT', 'RAVLT_forgetting',\n",
       "       'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_perc_forgetting', 'RID',\n",
       "       'SITE', 'TAU', 'TAU_bl', 'TRABSCOR', 'VISCODE', 'Ventricles',\n",
       "       'WholeBrain', 'Years_bl', 'mPACCdigit', 'mPACCtrailsB', 'update_stamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what features we have now\n",
    "baseline.columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have some columns that look very similar. These may contain non-numeric values such as strings or NaNs, or possibly they are really uncorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Baseline Missing Values</th>\n",
       "      <th>Percent Matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABETA</th>\n",
       "      <td>832</td>\n",
       "      <td>866</td>\n",
       "      <td>98.366170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DX</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>24.939933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXAMDATE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSVERSION</th>\n",
       "      <td>346</td>\n",
       "      <td>357</td>\n",
       "      <td>99.471408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTAU</th>\n",
       "      <td>832</td>\n",
       "      <td>866</td>\n",
       "      <td>98.366170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAU</th>\n",
       "      <td>832</td>\n",
       "      <td>866</td>\n",
       "      <td>98.366170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Missing Values  Baseline Missing Values  Percent Matching\n",
       "ABETA                 832                      866         98.366170\n",
       "DX                     25                       16         24.939933\n",
       "EXAMDATE                0                        0        100.000000\n",
       "FSVERSION             346                      357         99.471408\n",
       "PTAU                  832                      866         98.366170\n",
       "TAU                   832                      866         98.366170"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to check for duplicates\n",
    "cols = ['ABETA', 'DX', 'EXAMDATE','FSVERSION',  'PTAU', 'TAU']\n",
    "\n",
    "bl_missing = []\n",
    "missing = []\n",
    "matching_vals = []\n",
    "\n",
    "for col in cols:\n",
    "    missing.append(baseline[col].isnull().sum())\n",
    "    bl_missing.append(baseline[col+'_bl'].isnull().sum())\n",
    "    match = (baseline[col] == baseline[col+'_bl']).sum()\n",
    "    matching_vals.append((match + min(missing[-1], bl_missing[-1]))/len(baseline) * 100)\n",
    "                 \n",
    "# Display the results                \n",
    "bl_dupes = pd.DataFrame({'Missing Values': missing,\n",
    "                            'Baseline Missing Values': bl_missing,\n",
    "                            'Percent Matching': matching_vals}, index=cols)\n",
    "bl_dupes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the pairs are nearly exact duplicates except `DX`|`DX_bl`, so we can drop one of the duplicate columns. The baseline versions have slightly more missing data, so we'll drop those. Then we'll take a look at `DX` vs.`DX_bl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of duplicate column names to drop\n",
    "dupe_cols = [col + '_bl' for col in cols]\n",
    "\n",
    "# Remove DX_bl until we investigate further\n",
    "del dupe_cols[dupe_cols.index('DX_bl')]\n",
    "\n",
    "# Drop the columns\n",
    "baseline = baseline.drop(labels=dupe_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>DX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD</td>\n",
       "      <td>Dementia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LMCI</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SMC</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>EMCI</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DX_bl        DX\n",
       "0        CN        CN\n",
       "1        AD  Dementia\n",
       "5      LMCI       MCI\n",
       "48      SMC        CN\n",
       "2848   EMCI       MCI\n",
       "11389   NaN       NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how DX maps to DX_bl\n",
    "baseline.drop_duplicates('DX_bl')[['DX_bl', 'DX']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although similar, the diagnoses in `DX_bl` are more specific than those in `DX`. We'll use the more standard diagnosis codes in `DX`. However `DX_bl` has slightly less missingness so we'll keep that column and remap some of the values to match `DX` where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop DX\n",
    "baseline = baseline.drop(labels=['DX'], axis=1)\n",
    "\n",
    "# Remap some of the DX_bl values\n",
    "baseline.DX_bl = baseline.DX_bl.replace('LMCI','MCI')\n",
    "baseline.DX_bl = baseline.DX_bl.replace('EMCI','MCI')\n",
    "baseline.DX_bl = baseline.DX_bl.replace('SMC','CN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some participants for which we have no diagnosis code, so these records will not be useful and can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 16 participants with no diagnosis code.\n"
     ]
    }
   ],
   "source": [
    "missing_dx = len(baseline[baseline['DX_bl'].isnull()])\n",
    "baseline = baseline.dropna(axis=0, subset=['DX_bl'])\n",
    "print(f'Removed {missing_dx} participants with no diagnosis code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PTID` is also duplicative. It is a combination of `RID` and `SITE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.drop(labels='PTID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape of the baseline subset is (2065, 64).\n",
      "There are a total of 20821 missing values.\n",
      "Out of 64 features in the dataset, 44 have missing values.\n",
      "\n",
      "Quartiles of missing data:\n",
      "      Num Missing  Pct. Missing\n",
      "0.25        22.75      1.101695\n",
      "0.50       541.50     26.222760\n",
      "0.75       649.00     31.428571\n",
      "1.00      1974.00     95.593220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Missing</th>\n",
       "      <th>Pct. Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PIB</th>\n",
       "      <td>1974.0</td>\n",
       "      <td>95.593220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIGITSCOR</th>\n",
       "      <td>1248.0</td>\n",
       "      <td>60.435835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AV45</th>\n",
       "      <td>956.0</td>\n",
       "      <td>46.295400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABETA</th>\n",
       "      <td>816.0</td>\n",
       "      <td>39.515738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAU</th>\n",
       "      <td>816.0</td>\n",
       "      <td>39.515738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTAU</th>\n",
       "      <td>816.0</td>\n",
       "      <td>39.515738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogSPOrgan</th>\n",
       "      <td>670.0</td>\n",
       "      <td>32.445521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogSPDivatt</th>\n",
       "      <td>656.0</td>\n",
       "      <td>31.767554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogSPVisspat</th>\n",
       "      <td>654.0</td>\n",
       "      <td>31.670702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogSPPlan</th>\n",
       "      <td>651.0</td>\n",
       "      <td>31.525424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogSPTotal</th>\n",
       "      <td>649.0</td>\n",
       "      <td>31.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogSPMem</th>\n",
       "      <td>649.0</td>\n",
       "      <td>31.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogSPLang</th>\n",
       "      <td>648.0</td>\n",
       "      <td>31.380145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOCA</th>\n",
       "      <td>647.0</td>\n",
       "      <td>31.331719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogPtOrgan</th>\n",
       "      <td>644.0</td>\n",
       "      <td>31.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDG</th>\n",
       "      <td>643.0</td>\n",
       "      <td>31.138015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogPtDivatt</th>\n",
       "      <td>642.0</td>\n",
       "      <td>31.089588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogPtLang</th>\n",
       "      <td>640.0</td>\n",
       "      <td>30.992736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogPtVisspat</th>\n",
       "      <td>640.0</td>\n",
       "      <td>30.992736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogPtPlan</th>\n",
       "      <td>639.0</td>\n",
       "      <td>30.944310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogPtMem</th>\n",
       "      <td>638.0</td>\n",
       "      <td>30.895884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EcogPtTotal</th>\n",
       "      <td>638.0</td>\n",
       "      <td>30.895884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entorhinal</th>\n",
       "      <td>445.0</td>\n",
       "      <td>21.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fusiform</th>\n",
       "      <td>445.0</td>\n",
       "      <td>21.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MidTemp</th>\n",
       "      <td>445.0</td>\n",
       "      <td>21.549637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hippocampus</th>\n",
       "      <td>398.0</td>\n",
       "      <td>19.273608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ventricles</th>\n",
       "      <td>358.0</td>\n",
       "      <td>17.336562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WholeBrain</th>\n",
       "      <td>346.0</td>\n",
       "      <td>16.755448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APOE4</th>\n",
       "      <td>340.0</td>\n",
       "      <td>16.464891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSVERSION</th>\n",
       "      <td>330.0</td>\n",
       "      <td>15.980630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMAGEUID</th>\n",
       "      <td>330.0</td>\n",
       "      <td>15.980630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICV</th>\n",
       "      <td>330.0</td>\n",
       "      <td>15.980630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRABSCOR</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1.259080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAQ</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.629540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAVLT_perc_forgetting</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.387409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAS13</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.387409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAS11</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.290557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDELTOTAL</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAVLT_forgetting</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAVLT_learning</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAVLT_immediate</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADASQ4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mPACCdigit</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mPACCtrailsB</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Num Missing  Pct. Missing\n",
       "PIB                         1974.0     95.593220\n",
       "DIGITSCOR                   1248.0     60.435835\n",
       "AV45                         956.0     46.295400\n",
       "ABETA                        816.0     39.515738\n",
       "TAU                          816.0     39.515738\n",
       "PTAU                         816.0     39.515738\n",
       "EcogSPOrgan                  670.0     32.445521\n",
       "EcogSPDivatt                 656.0     31.767554\n",
       "EcogSPVisspat                654.0     31.670702\n",
       "EcogSPPlan                   651.0     31.525424\n",
       "EcogSPTotal                  649.0     31.428571\n",
       "EcogSPMem                    649.0     31.428571\n",
       "EcogSPLang                   648.0     31.380145\n",
       "MOCA                         647.0     31.331719\n",
       "EcogPtOrgan                  644.0     31.186441\n",
       "FDG                          643.0     31.138015\n",
       "EcogPtDivatt                 642.0     31.089588\n",
       "EcogPtLang                   640.0     30.992736\n",
       "EcogPtVisspat                640.0     30.992736\n",
       "EcogPtPlan                   639.0     30.944310\n",
       "EcogPtMem                    638.0     30.895884\n",
       "EcogPtTotal                  638.0     30.895884\n",
       "Entorhinal                   445.0     21.549637\n",
       "Fusiform                     445.0     21.549637\n",
       "MidTemp                      445.0     21.549637\n",
       "Hippocampus                  398.0     19.273608\n",
       "Ventricles                   358.0     17.336562\n",
       "WholeBrain                   346.0     16.755448\n",
       "APOE4                        340.0     16.464891\n",
       "FSVERSION                    330.0     15.980630\n",
       "IMAGEUID                     330.0     15.980630\n",
       "ICV                          330.0     15.980630\n",
       "TRABSCOR                      26.0      1.259080\n",
       "FAQ                           13.0      0.629540\n",
       "RAVLT_perc_forgetting          8.0      0.387409\n",
       "ADAS13                         8.0      0.387409\n",
       "ADAS11                         6.0      0.290557\n",
       "LDELTOTAL                      3.0      0.145278\n",
       "RAVLT_forgetting               3.0      0.145278\n",
       "RAVLT_learning                 3.0      0.145278\n",
       "RAVLT_immediate                3.0      0.145278\n",
       "ADASQ4                         3.0      0.145278\n",
       "mPACCdigit                     2.0      0.096852\n",
       "mPACCtrailsB                   2.0      0.096852"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The new shape of the baseline subset is {}.\".format(baseline.shape))\n",
    "utils.calculate_missing_data(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new dataset, it is clear that `PIB` will not be useful and can be removed. PIB or *PiB* stands for **Pi**ttsburgh Compound-**B** - a synthetic radiotracer developed for use in PET scans to visualize and measure A$\\beta$ deposits in the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.drop(labels='PIB', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other features in the data that we are confindent won't be helpful in predicting AD. These include features such as `SITE`, `update_stamp`, `EXAMDATE`, etc. We will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline.drop(labels=['update_stamp', 'Years_bl', 'SITE', 'VISCODE', 'COLPROT', 'ORIGPROT',\n",
    "                                 'Month_bl', 'M', 'EXAMDATE', 'IMAGEUID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ABETA', 'ADAS11', 'ADAS13', 'ADASQ4', 'AGE', 'APOE4', 'AV45', 'CDRSB',\n",
       "       'DIGITSCOR', 'DX_bl', 'EcogPtDivatt', 'EcogPtLang', 'EcogPtMem',\n",
       "       'EcogPtOrgan', 'EcogPtPlan', 'EcogPtTotal', 'EcogPtVisspat',\n",
       "       'EcogSPDivatt', 'EcogSPLang', 'EcogSPMem', 'EcogSPOrgan', 'EcogSPPlan',\n",
       "       'EcogSPTotal', 'EcogSPVisspat', 'Entorhinal', 'FAQ', 'FDG', 'FSVERSION',\n",
       "       'Fusiform', 'Hippocampus', 'ICV', 'LDELTOTAL', 'MMSE', 'MOCA',\n",
       "       'MidTemp', 'Month', 'PTAU', 'PTEDUCAT', 'PTETHCAT', 'PTGENDER',\n",
       "       'PTMARRY', 'PTRACCAT', 'RAVLT_forgetting', 'RAVLT_immediate',\n",
       "       'RAVLT_learning', 'RAVLT_perc_forgetting', 'RID', 'TAU', 'TRABSCOR',\n",
       "       'Ventricles', 'WholeBrain', 'mPACCdigit', 'mPACCtrailsB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what features we have now\n",
    "baseline.columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some non-numeric data in `ABETA`, `TAU`, and `PTAU`, such as '>1300' or '<80'. We'll remove the `>` and `<` characters and change the dtype to float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove < or > \n",
    "def remove_gt_lt(val):\n",
    "    if type(val) == str:\n",
    "        return float(val.replace('>', '').replace('<', ''))\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "    \n",
    "for col in ['ABETA', 'TAU', 'PTAU']:\n",
    "    values = baseline[col].values\n",
    "    baseline[col] = list(map(remove_gt_lt, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline['PTEDUCAT'] = baseline.PTEDUCAT.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have cleaned the data by removing duplicate/highly correlated or informationless features and filling in missing values that can be found within the collected data. To deal with the remaining missingness, we will impute values. But first we have to make a decision about whether to normalize the data before or after imputation. We have decided to standardize the data before imputing missing values. We reason that imputing on the data before standardization may cover up or dilute any bias present in the data. Also, standardizing the data before imputation is preferred if we use modeling to impute missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are additional (potentially valuable) data that are not included in the Merged data set. These data have been cleaned and put into a format such that we can join them to the merged data set. We will do that before performing any imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set the baseline index to 'RID'\n",
    "baseline.index = baseline['RID']\n",
    "baseline = baseline.drop(labels='RID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the additional patient data. Use RID as the index column\n",
    "pat_data = pd.read_csv('../data/Per_Patient/patient_firstidx_merge.csv', index_col='RID', na_values='-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify and remove any duplicate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped duplicate columns: ['ABETA', 'PTEDUCAT', 'PTETHCAT', 'PTMARRY', 'TAU', 'PTRACCAT', 'PTGENDER', 'PTAU']\n"
     ]
    }
   ],
   "source": [
    "dupes = list(set(baseline.columns) & set(pat_data.columns))\n",
    "pat_data = pat_data.drop(labels=dupes, axis=1)\n",
    "print(f'Dropped duplicate columns: {dupes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll merge the ADNI_Merge dataset and cleaned Per_Patient dataset that we've built and curated from raw data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge baseline with pat_data\n",
    "pat_comb = pd.merge(baseline, pat_data, on='RID')\n",
    "\n",
    "# First drop cols that have only NA values\n",
    "pat_comb = pat_comb.dropna(axis='columns', thresh=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the file before imputing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_comb.to_csv('../data/Per_Patient/pat_merge_b4_impute.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to strike a balance between keeping as much data as possible and reducing noise introduced by imputing columns that are nearly completely void of information. We will explore the relationship between these by imputing with different thresholds for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_cols(data, threshold):\n",
    "    \"\"\"Drops cols from data that missing values above the threshold.\n",
    "    \n",
    "    # Arguments:\n",
    "        data: The data to drop missing cols from\n",
    "        threshold: float 0:1, the max allowable percentage of missing values\n",
    "        \n",
    "    # Returns\n",
    "        The data with missing cols dropped.\n",
    "    \"\"\"\n",
    "    cols = data.columns.values\n",
    "\n",
    "    # Drop columns that don't have at least 1 - threshold non-NA values\n",
    "    data = data.dropna(axis='columns', thresh=np.floor(data.shape[0] * (1 - threshold)))\n",
    "\n",
    "    print('Dropped columns due to missingness:\\n', set(cols) ^ set(data.columns.values))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will prepare the categorical variables. Depending on the study, some categorical features use text values like `AD`, `MCI`, `MALE`, `FEMALE`, etc., and some use numerical codes. The per-patient data have been cleaned to and standardized to use numeric values. We will read in a file that identifies the correct dtypes per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_data(missing_thresh):\n",
    "    \"\"\"Gets the raw combined (ADNI_Merge and Per_Patient) datasets. The\n",
    "    categorical features will have a dtype of 'int'. \n",
    "    \n",
    "    # Returns:\n",
    "        Returns the combined (ADNI_Merge and Per_Patient) datasets and lists\n",
    "        of the categorical and non-categorical features.\n",
    "    \"\"\"\n",
    "    # Read in the combined (Merged and Per Patient) dataset\n",
    "    pat_comb = pd.read_csv('../data/Per_Patient/pat_merge_b4_impute.csv', index_col='RID')\n",
    "    \n",
    "    # Drop cols based on missing threshold\n",
    "    pat_comb = drop_missing_cols(pat_comb, missing_thresh)\n",
    "\n",
    "    # Import the dtypes. Categorical variables are represented as int64 as opposed to floats.\n",
    "    dtypes = pd.read_csv('../data/Per_Patient/patient_firstidx_dtypes.csv', index_col='feature_name')\n",
    "\n",
    "    # Categoricals from baseline\n",
    "    categoricals = ['PTETHCAT', 'PTGENDER', 'PTRACCAT', 'PTMARRY', 'FSVERSION', 'APOE4', 'DX_bl']\n",
    "    for cat in categoricals:\n",
    "        if cat not in pat_comb.columns:\n",
    "            categoricals.pop(categoricals.index(cat))\n",
    "\n",
    "    # Collect categorical columns from pat_data based on dtype=int64\n",
    "    for i in dtypes.index:\n",
    "        # RID is the index so skip it\n",
    "        if i == 'RID':\n",
    "            continue\n",
    "        # If dtype is int, the it's categorical\n",
    "        if 'int' in dtypes.loc[i].data_type and i in pat_comb.columns:\n",
    "            categoricals.append(i)\n",
    "\n",
    "    # Remove any dupes\n",
    "    categoricals = list(set(categoricals))\n",
    "    non_cat = list(set(pat_comb.columns) ^ set(categoricals))\n",
    "    return pat_comb, categoricals, non_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the missing data threshold\n",
    "missing_thresh = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have cleaned the data by removing duplicate/highly correlated or informationless features and filling in missing values that can be found within the collected data. To deal with the remaining missingness, we will impute values. But first we have to make a decision about whether to normalize the data before or after imputation. We have decided to normalize the data before imputing missing values. We reason that imputing on the data before normalization may cover up or dilute any bias present in the data. Also, normalizing the data before imputation is preferred if we use modeling to impute missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns due to missingness:\n",
      " {'DXMPTR1', 'MH14AALCH', 'MH16ASMOK', 'HMT95', 'CMT2', 'HMT93', 'DXMPTR4', 'MH15ADRUG', 'CMT3', 'HMT96', 'HMT21', 'DXNORM', 'DIGITSCOR', 'DADAD', 'MH16BSMOK', 'DXMPTR2', 'HMT20', 'AXT117', 'DXNODEP', 'HMT69', 'DXMPTR5', 'MH15BDRUG', 'UAT3', 'UAT2', 'MH16CSMOK', 'MH14BALCH', 'MH14CALCH', 'BAT324', 'DXMPTR3', 'HMT98', 'HMT70'}\n"
     ]
    }
   ],
   "source": [
    "# Read in data and identify categorical and non-categorical features\n",
    "pat_comb, categoricals, non_cat = get_combined_data(missing_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Scale all columns that are non-categorical\n",
    "pat_comb = utils.scale_cols(data=pat_comb, cols=non_cat, scaler=MinMaxScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use a combination of stacking and grid search to see the effects of missingness and different models on imputation and predictive models. We'll start by defining the classifiers and regressors that we want to evaluate for imputing the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clf_stack():\n",
    "    \"\"\"Convenience function to create a stacking meta classifier.\n",
    "    \n",
    "    # Returns:\n",
    "        A Stacking CV Classifier and a parameter grid.\n",
    "    \"\"\"\n",
    "    # Define classification estimators and their param grids\n",
    "    cl_params = {}\n",
    "\n",
    "    # SVC\n",
    "    svc = SVC(gamma='scale', decision_function_shape='ovr', probability=True, class_weight='balanced')\n",
    "    bclf = BaggingClassifier(svc, max_samples=.5, max_features=.5, n_estimators=10, n_jobs=-1)\n",
    "    clf1 = OneVsRestClassifier(bclf, n_jobs=-1)\n",
    "    cl_params['onevsrestclassifier__estimator__base_estimator__kernel'] = ['linear', 'rbf']\n",
    "    cl_params['onevsrestclassifier__estimator__base_estimator__C'] = 10. ** np.arange(-2, 2)\n",
    "\n",
    "    # AdaBoost\n",
    "    dtc = DecisionTreeClassifier(max_features=\"auto\", class_weight=\"balanced\", max_depth=None)\n",
    "    clf2 = AdaBoostClassifier(base_estimator=dtc)\n",
    "    cl_params['adaboostclassifier__base_estimator__criterion'] = [\"gini\"]\n",
    "    cl_params['adaboostclassifier__n_estimators'] = [100]\n",
    "\n",
    "    # KNN\n",
    "    clf3 = KNeighborsClassifier(n_jobs=-1)\n",
    "    cl_params['kneighborsclassifier__n_neighbors'] = [2, 5, 10, 100]\n",
    "\n",
    "    # Meta-classifier\n",
    "    meta_clf = LogisticRegression(solver='lbfgs', n_jobs=-1, multi_class='auto')\n",
    "    #cl_params['meta-logisticregression__C'] = [0.1, 1, 10.0]\n",
    "\n",
    "    # Stacking-Classifier\n",
    "    sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3],\n",
    "                                meta_classifier=meta_clf)\n",
    "    \n",
    "    return sclf, cl_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 1 of 80: MH3HEAD\n",
      "Imputing feature 2 of 80: BCDIZZY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 3 of 80: BCANKLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 4 of 80: DXDEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 5 of 80: MH17MALI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 6 of 80: NXSENSOR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 7 of 80: BCINSOMN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 8 of 80: FSVERSION\n",
      "Error fitting values for FSVERSION\n",
      "Cross-Sectional FreeSurfer (5.1)                       916\n",
      "Cross-Sectional FreeSurfer (FreeSurfer Version 4.3)    819\n",
      "Name: FSVERSION, dtype: int64\n",
      "Imputing feature 9 of 80: NXVISUAL\n",
      "Imputing feature 10 of 80: PTHAND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 11 of 80: MH2NEURL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 12 of 80: NXAUDITO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 13 of 80: BCDROWSY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 14 of 80: BCURNFRQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 15 of 80: NXABNORM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fitting values for NXABNORM\n",
      "1.0    2046\n",
      "2.0       2\n",
      "Name: NXABNORM, dtype: int64\n",
      "Imputing feature 16 of 80: BCVOMIT\n",
      "Error fitting values for BCVOMIT\n",
      "1.0    1719\n",
      "2.0      20\n",
      "Name: BCVOMIT, dtype: int64\n",
      "Imputing feature 17 of 80: BCSWEATN\n",
      "Imputing feature 18 of 80: MOMAD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 19 of 80: DADDEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 20 of 80: MH13ALLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 21 of 80: NXCONSCI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fitting values for NXCONSCI\n",
      "1.0    2047\n",
      "2.0       3\n",
      "Name: NXCONSCI, dtype: int64\n",
      "Imputing feature 22 of 80: NXTREMOR\n",
      "Imputing feature 23 of 80: BCELMOOD\n",
      "Error fitting values for BCELMOOD\n",
      "1.0    1720\n",
      "2.0      19\n",
      "Name: BCELMOOD, dtype: int64\n",
      "Imputing feature 25 of 80: BCENERGY\n",
      "Imputing feature 27 of 80: NXHEEL\n",
      "Error fitting values for NXHEEL\n",
      "1.0    2015\n",
      "2.0      34\n",
      "Name: NXHEEL, dtype: int64\n",
      "Imputing feature 28 of 80: BCABDOMN\n",
      "Imputing feature 29 of 80: DX_BASE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 30 of 80: APGEN2\n",
      "Error fitting values for APGEN2\n",
      "3.0    911\n",
      "4.0    809\n",
      "2.0      5\n",
      "Name: APGEN2, dtype: int64\n",
      "Imputing feature 31 of 80: MH16SMOK\n",
      "Imputing feature 32 of 80: MH10GAST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 33 of 80: MH14ALCH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 35 of 80: BCBREATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 36 of 80: DX_CHANGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fitting values for DX_CHANGE\n",
      "1.0    659\n",
      "5.0    573\n",
      "9.0    325\n",
      "8.0    288\n",
      "4.0     85\n",
      "2.0     60\n",
      "7.0     20\n",
      "6.0      4\n",
      "Name: DX_CHANGE, dtype: int64\n",
      "Imputing feature 37 of 80: BCWANDER\n",
      "Error fitting values for BCWANDER\n",
      "1.0    1732\n",
      "2.0       7\n",
      "Name: BCWANDER, dtype: int64\n",
      "Imputing feature 38 of 80: NXPLANTA\n",
      "Imputing feature 39 of 80: DX_FINAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 40 of 80: BCCONSTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 41 of 80: MOMDEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fitting values for MOMDEM\n",
      "0.0    1203\n",
      "1.0     822\n",
      "2.0      33\n",
      "Name: MOMDEM, dtype: int64\n",
      "Imputing feature 42 of 80: MH18SURG\n",
      "Imputing feature 43 of 80: NXNERVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 44 of 80: MHPSYCH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 45 of 80: MH6HEPAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 46 of 80: NXOTHER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 48 of 80: BCCOUGH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 49 of 80: BCMUSCLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 50 of 80: BCNAUSEA\n",
      "Imputing feature 51 of 80: BCFALL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 52 of 80: DXCOMB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 54 of 80: BCDPMOOD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 55 of 80: DXPARK\n",
      "Error fitting values for DXPARK\n",
      "0.0    1228\n",
      "1.0      11\n",
      "Name: DXPARK, dtype: int64\n",
      "Imputing feature 57 of 80: MH9ENDO\n",
      "Imputing feature 58 of 80: MH12RENA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 59 of 80: APGEN1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 60 of 80: BCURNDIS\n",
      "Error fitting values for BCURNDIS\n",
      "1.0    1699\n",
      "2.0      40\n",
      "Name: BCURNDIS, dtype: int64\n",
      "Imputing feature 61 of 80: BCPALPIT\n",
      "Imputing feature 62 of 80: MH15DRUG\n",
      "Error fitting values for MH15DRUG\n",
      "0.0    1726\n",
      "1.0      13\n",
      "Name: MH15DRUG, dtype: int64\n",
      "Imputing feature 63 of 80: NXGAIT\n",
      "Imputing feature 64 of 80: BCCHEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fitting values for BCCHEST\n",
      "1.0    1707\n",
      "2.0      32\n",
      "Name: BCCHEST, dtype: int64\n",
      "Imputing feature 65 of 80: BCHDACHE\n",
      "Imputing feature 66 of 80: MH4CARD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 67 of 80: NXMOTOR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 68 of 80: BCDRYMTH\n",
      "Imputing feature 69 of 80: MH5RESP\n",
      "Imputing feature 70 of 80: BCDIARRH\n",
      "Imputing feature 71 of 80: BCRASH\n",
      "Imputing feature 72 of 80: MH8MUSCL\n",
      "Imputing feature 73 of 80: NXTENDON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 74 of 80: MH7DERM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 76 of 80: BCCRYING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 77 of 80: BCVISION\n",
      "Imputing feature 78 of 80: APOE4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 79 of 80: NXFINGER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 80 of 80: MH11HEMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "impute_thresh = .25\n",
    "sclf, cl_params = make_clf_stack()\n",
    "\n",
    "pat_comb, imputed_cols, scores, errors = utils.impute_values_classification(pat_comb,\n",
    "                                                      cols=categoricals,\n",
    "                                                      estimator=sclf,\n",
    "                                                      param_grid=cl_params,\n",
    "                                                      impute_thresh=impute_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save imputed data\n",
    "clf_data_file = f'../data/Imputed/Combined/data_missing{missing_thresh}_StackingCVClassifier_impute{impute_thresh}.csv'\n",
    "pat_comb.to_csv(clf_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and scores\n",
    "models, m_score = list(map(list, zip(*scores)))\n",
    "\n",
    "def name_model(model, col):\n",
    "    nm = model.__repr__().split('(')[0]\n",
    "    return f\"{col}_{missing_thresh}_{nm}_{impute_thresh}\"\n",
    "\n",
    "model_names = [name_model(model, col) for model, col in zip(models, imputed_cols)]\n",
    "\n",
    "\n",
    "scores_pd = pd.DataFrame({'Score': m_score, 'Model': model_names}, index=imputed_cols)\n",
    "scores_pd.index.name = 'Feature'\n",
    "clf_scores_file = f'../data/Imputed/Combined/scores_missing{missing_thresh}_StackingCVClassifier_impute{impute_thresh}.csv'\n",
    "scores_pd.to_csv(clf_scores_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MH3HEAD</th>\n",
       "      <td>0.654399</td>\n",
       "      <td>MH3HEAD_0.5_StackingCVClassifier_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCDIZZY</th>\n",
       "      <td>0.867740</td>\n",
       "      <td>BCDIZZY_0.5_StackingCVClassifier_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCANKLE</th>\n",
       "      <td>0.901668</td>\n",
       "      <td>BCANKLE_0.5_StackingCVClassifier_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXDEP</th>\n",
       "      <td>0.923423</td>\n",
       "      <td>DXDEP_0.5_StackingCVClassifier_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MH17MALI</th>\n",
       "      <td>0.764807</td>\n",
       "      <td>MH17MALI_0.5_StackingCVClassifier_0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Score                                   Model\n",
       "Feature                                                   \n",
       "MH3HEAD   0.654399   MH3HEAD_0.5_StackingCVClassifier_0.25\n",
       "BCDIZZY   0.867740   BCDIZZY_0.5_StackingCVClassifier_0.25\n",
       "BCANKLE   0.901668   BCANKLE_0.5_StackingCVClassifier_0.25\n",
       "DXDEP     0.923423     DXDEP_0.5_StackingCVClassifier_0.25\n",
       "MH17MALI  0.764807  MH17MALI_0.5_StackingCVClassifier_0.25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_pd = pd.read_csv(clf_scores_file, index_col='Feature')\n",
    "scores_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save errors\n",
    "err_file = f'../data/Imputed/Combined/errors_missing{missing_thresh}_StackingCVClassifier_impute{impute_thresh}.csv'\n",
    "try:\n",
    "    pd.Series(errors).to_csv(err_file)\n",
    "except:\n",
    "    print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reg_stack():\n",
    "    \"\"\"Convenience function to create a stacking meta regressor.\n",
    "    \n",
    "    # Returns:\n",
    "        A Stacking CV Regressor and a parameter grid.\n",
    "    \"\"\"\n",
    "    # Define regression estimators and their param grids\n",
    "    reg_params = {}\n",
    "\n",
    "    # Lasso estimator\n",
    "    reg1 = linear_model.Lasso(selection='random', max_iter=3000)\n",
    "    reg_params['lasso__alpha'] = [.001, .01, .1]\n",
    "    \n",
    "    # Ridge estimator\n",
    "    reg2 = linear_model.Ridge(max_iter=3000)\n",
    "    reg_params['ridge__alpha'] = [.001, .01, .1]\n",
    "    \n",
    "    reg3 = SVR(kernel='rbf', gamma='auto')\n",
    "    reg_params['svr__C'] = [.01, 1, 10, 100]\n",
    "    \n",
    "    # RandomForest estimator\n",
    "    meta_reg = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True)\n",
    "    reg_params['meta-randomforestregressor__min_samples_leaf'] = [3, 10, 50, 100]\n",
    "\n",
    "\n",
    "    reg_stack = StackingCVRegressor(regressors=(reg1, reg2, reg3),\n",
    "                            meta_regressor=meta_reg, \n",
    "                            use_features_in_secondary=True)\n",
    "    \n",
    "    return reg_stack, reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in imputed (classification) data\n",
    "impute_thresh = .25\n",
    "pat_comb = pd.read_csv(clf_data_file, index_col='RID', na_values='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 1 of 85: RCT1407\n",
      "Imputing feature 2 of 85: EcogPtMem\n",
      "Imputing feature 3 of 85: FDG\n",
      "Imputing feature 4 of 85: RCT11\n",
      "Imputing feature 5 of 85: MOCA\n",
      "Imputing feature 6 of 85: EcogPtTotal\n",
      "Imputing feature 7 of 85: RCT29\n",
      "Imputing feature 9 of 85: EcogSPMem\n",
      "Imputing feature 10 of 85: WholeBrain\n",
      "Imputing feature 11 of 85: MidTemp\n",
      "Imputing feature 12 of 85: HMT10\n",
      "Imputing feature 13 of 85: EcogSPDivatt\n",
      "Imputing feature 14 of 85: RCT4\n",
      "Imputing feature 15 of 85: EcogSPOrgan\n",
      "Imputing feature 16 of 85: HMT40\n",
      "Imputing feature 17 of 85: HMT12\n",
      "Imputing feature 18 of 85: RCT8\n",
      "Imputing feature 19 of 85: RCT1\n",
      "Imputing feature 20 of 85: EcogSPLang\n",
      "Imputing feature 21 of 85: EcogPtDivatt\n",
      "Imputing feature 23 of 85: HMT19\n",
      "Imputing feature 24 of 85: RCT6\n",
      "Imputing feature 25 of 85: RCT183\n",
      "Imputing feature 26 of 85: HMT11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 27 of 85: GDTOTAL\n",
      "Imputing feature 28 of 85: FAQ\n",
      "Imputing feature 29 of 85: RCT20\n",
      "Imputing feature 30 of 85: RCT5\n",
      "Imputing feature 31 of 85: Fusiform\n",
      "Imputing feature 32 of 85: HMT7\n",
      "Imputing feature 33 of 85: EcogSPPlan\n",
      "Imputing feature 34 of 85: HMT13\n",
      "Imputing feature 35 of 85: RCT9\n",
      "Imputing feature 36 of 85: RCT14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 38 of 85: EcogPtPlan\n",
      "Imputing feature 39 of 85: AV45\n",
      "Imputing feature 40 of 85: ICV\n",
      "Imputing feature 41 of 85: HMT3\n",
      "Imputing feature 42 of 85: HMT8\n",
      "Imputing feature 43 of 85: MMSCORE\n",
      "Imputing feature 44 of 85: EcogPtLang\n",
      "Imputing feature 45 of 85: RCT12\n",
      "Imputing feature 46 of 85: EcogSPTotal\n",
      "Imputing feature 47 of 85: RCT3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing feature 48 of 85: HMT18\n",
      "Imputing feature 49 of 85: HMT2\n",
      "Imputing feature 50 of 85: HMT17\n",
      "Imputing feature 51 of 85: BAT126\n",
      "Imputing feature 52 of 85: ABETA\n",
      "Imputing feature 53 of 85: ADASQ4\n",
      "Imputing feature 54 of 85: HMT15\n",
      "Imputing feature 55 of 85: mPACCtrailsB\n",
      "Imputing feature 57 of 85: LDELTOTAL\n",
      "Imputing feature 58 of 85: HMT16\n",
      "Imputing feature 59 of 85: ADAS11\n",
      "Imputing feature 60 of 85: EcogPtOrgan\n"
     ]
    }
   ],
   "source": [
    "reg_stack, reg_params = make_reg_stack()\n",
    "pat_comb, imputed_cols, scores = utils.impute_values_regression(pat_comb,\n",
    "                                                      cols=non_cat,\n",
    "                                                      estimator=reg_stack,\n",
    "                                                      param_grid=reg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save imputed data\n",
    "final_data_file = f'../data/Imputed/Combined/data_missing{missing_thresh}_StackingCVRegressor_impute{impute_thresh}.csv'\n",
    "pat_comb.to_csv(final_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and scores\n",
    "models, m_score = list(map(list, zip(*scores)))\n",
    "\n",
    "def name_model(model, col):\n",
    "    nm = model.__repr__().split('(')[0]\n",
    "    return f\"{col}_{missing_thresh}_{nm}_{impute_thresh}\"\n",
    "\n",
    "model_names = [name_model(model, col) for model, col in zip(models, imputed_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scores\n",
    "scores_pd = pd.read_csv(clf_scores_file, index_col='Feature')\n",
    "df = pd.DataFrame({'Score': m_score, 'Model': model_names}, index=imputed_cols)\n",
    "df.index.name = 'Feature'\n",
    "scores_pd = pd.concat([scores_pd, df], sort=True)\n",
    "final_scores_file = f'../data/Imputed/Combined/scores_missing{missing_thresh}_StackingCVRegressor_impute{impute_thresh}.csv'\n",
    "scores_pd.to_csv(final_scores_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
